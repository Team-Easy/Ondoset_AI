{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# latent factor의 수\n",
    "num_features = 30\n",
    "# iteration 수\n",
    "iterations = 140\n",
    "# learning_rate \n",
    "learning_rate = 1e-1\n",
    "# lambda\n",
    "lambda_ = 1\n",
    "# count_weight\n",
    "count_weight = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'df_merged'"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# csv 파일을 dataframe으로 변환\n",
    "df_outfit = pd.read_csv('../data/outfit(male)/outfit(male).csv')\n",
    "df_weather = pd.read_csv('../data/2022-08-01_to_2024-04-30.csv', encoding='cp949')\n",
    "# 필요한 columns만 추출\n",
    "df_outfit = df_outfit[['userId', '상의', '아우터', '하의', '신발', '액세서리', '작성일']].copy()\n",
    "df_temp = df_weather[['일시', '평균기온(°C)']].copy()\n",
    "\n",
    "# '작성일'과 '일시' 열을 datetime 형식으로 변환\n",
    "df_outfit['작성일'] = pd.to_datetime(df_outfit['작성일'], format='%Y년 %m월 %d일')\n",
    "df_temp['일시'] = pd.to_datetime(df_temp['일시'])\n",
    "\n",
    "# 두 dataframe을 날짜를 기준으로 병합\n",
    "df_merged = pd.merge(df_outfit, df_temp, left_on='작성일', right_on='일시').drop('일시', axis=1)\n",
    "\n",
    "'''df_merged'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '상의', '아우터', '하의', '신발', '엑세서리' 열의 결측값을 '~ 없음'으로 대체\n",
    "columns = ['상의', '아우터', '하의', '신발', '액세서리']\n",
    "df_notnull = df_merged.copy()\n",
    "for column in columns:\n",
    "    df_notnull[column] = df_merged[column].fillna(column + ' 없음')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"df_notnull[df_notnull['아우터'].str.contains('재킷 2')]\""
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''df_notnull[df_notnull['아우터'].str.contains('재킷 2')]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"df_dup[df_dup['아우터'].str.contains('니트')]\""
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''df_dup[df_dup['아우터'].str.contains('니트')]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2가 붙은 단어를 두 번 반복하는 함수\n",
    "def duplicate_word(text):\n",
    "    words = text.split(', ')\n",
    "    for i, word in enumerate(words):\n",
    "        if '2' in word:\n",
    "            words[i] = word.replace('2', '') + ', ' + word.replace('2', '')\n",
    "    return ', '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2가 붙은 단어를 두 번 반복한 dataframe df_dup 생성\n",
    "df_dup = df_notnull.copy()\n",
    "for column in columns:\n",
    "    df_dup[columns] = df_notnull[columns].map(duplicate_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'df_dup.columns'"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''df_dup.columns'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 옷의 조합 컬럼 생성 (상의, 아우터, 하의, 신발, 엑세서리의 각 값들을 하나의 문자열로 조합하여 하나의 컬럼으로 만듦)\n",
    "df_combination = df_dup.copy()\n",
    "df_combination['옷 조합'] = df_dup['상의'] + ', ' + df_dup['아우터'] + ', ' + df_dup['하의'] + ', ' + df_dup['신발'] + ', ' + df_dup['액세서리']\n",
    "df_combination.drop(columns=['상의', '아우터', '하의', '신발', '액세서리'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'df_combination.columns'"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''df_combination.columns'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"df_combination[df_combination['옷 조합'].str.contains('니트 , 니트')]\""
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''df_combination[df_combination['옷 조합'].str.contains('니트 , 니트')]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# 옷의 조합 컬럼의 공백 제거\\ndf_combination['옷 조합'] = df_combination['옷 조합'].str.replace(' ', '')\""
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# 옷의 조합 컬럼의 공백 제거\n",
    "df_combination['옷 조합'] = df_combination['옷 조합'].str.replace(' ', '')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ksy/anaconda3/envs/ondoset/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'npa.shape'"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 쉼표를 기준으로 텍스트를 나누는 함수\n",
    "def comma_tokenizer(s):\n",
    "    return s.split(', ')\n",
    "\n",
    "vectorizer = CountVectorizer(tokenizer=comma_tokenizer)\n",
    "\n",
    "O = vectorizer.fit_transform(df_combination['옷 조합'])\n",
    "\n",
    "# multi-hot encoding된 데이터를 numpy array로 변환\n",
    "df_encoded = pd.DataFrame(O.toarray().tolist(), columns=vectorizer.get_feature_names_out())\n",
    "npa = np.array(df_encoded)\n",
    "'''npa.shape'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([86, 317, 430, 435, 560, 593, 633, 640, 793, 1039], dtype='int64')"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 값이 2 이상인 행의 인덱스\n",
    "rows_with_value_2 = df_encoded[(df_encoded >= 2).any(axis=1)]\n",
    "rows_with_value_2.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'record'"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 값이 2 이상인 열의 이름을 찾습니다.\n",
    "columns_with_value_over_2 = df_encoded.columns[(df_encoded >= 2).any()]\n",
    "\n",
    "# 특정 행에 대해 이를 기록합니다.\n",
    "record = df_encoded.loc[rows_with_value_2.index, columns_with_value_over_2]\n",
    "'''record'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['가디건', '가죽 바지', '구두/로퍼', '기타 모자', '긴팔 티', '나일론 팬츠', '니트', '데님팬츠',\n",
       "       '레더부츠', '레인부츠', '마스크', '맨투맨', '머플러', '면바지', '민소매 티', '바람막이', '반바지',\n",
       "       '반팔 니트', '반팔 셔츠/블라우스', '반팔 티', '비니', '샌들/슬리퍼', '셔츠/블라우스',\n",
       "       '스니커즈/캔버스', '스카프', '슬랙스', '아우터 없음', '액세서리 없음', '양말', '운동화', '장목양말',\n",
       "       '재킷', '점퍼', '조끼', '집업', '카고바지', '코트', '털 모자', '트레이닝/조거 팬츠', '패딩',\n",
       "       '패딩슈즈', '패딩조끼', '하의 없음', '후드티'], dtype=object)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 단어장 확인\n",
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"df_combination['옷 조합']\""
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numpy array를 list로 변환 후 clothes_combination 컬럼에 대입\n",
    "df_combination['옷 조합'] = npa.tolist()\n",
    "'''df_combination['옷 조합']'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"df_combination['옷 조합'] \""
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# multi-hot encoding된 데이터를 다시 텍스트로 변환\n",
    "df_combination['옷 조합'] = vectorizer.inverse_transform(npa)\n",
    "'''df_combination['옷 조합'] '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하나의 문자열로 변환\n",
    "df_combtest = df_combination.copy()\n",
    "df_combtest['옷 조합'] = df_combination['옷 조합'].apply(lambda x: ', '.join(map(str, x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>작성일</th>\n",
       "      <th>평균기온(°C)</th>\n",
       "      <th>옷 조합</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [userId, 작성일, 평균기온(°C), 옷 조합]\n",
       "Index: []"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combtest[df_combtest['옷 조합'].str.contains('반팔,')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi-hot encoding의 값이 2 이상인 경우, 해당 단어를 두 번 반복\n",
    "for i in record.index:\n",
    "    old_value = df_combtest.loc[i, '옷 조합']\n",
    "    for col in record.columns:\n",
    "        if record.loc[i, col] >= 2:\n",
    "            old_value = old_value.replace(col, col + ', ' + col)\n",
    "    df_combtest.loc[i, '옷 조합'] = old_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"df_combtest.loc[rows_with_value_2.index, '옷 조합']\""
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''df_combtest.loc[rows_with_value_2.index, '옷 조합']'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'df_combtest'"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''df_combtest'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'print(max_temp, min_temp)'"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 평균기온(°C) column의 최대값과 최솟값\n",
    "max_temp = df_combtest['평균기온(°C)'].max()\n",
    "min_temp = df_combtest['평균기온(°C)'].min()\n",
    "'''print(max_temp, min_temp)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'df_limit'"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_limit = df_combtest.copy()\n",
    "# 평균기온(°C) column을 5도 간격으로 범주화하여 0, 1, 2, ...로 변환\n",
    "bins=np.round(np.arange(min_temp -5, max_temp+5, 5), 1)\n",
    "labels=np.arange(0, (max_temp-min_temp)//5+2)\n",
    "df_limit['평균기온(°C)'] = pd.cut(df_limit['평균기온(°C)'], bins=bins, labels=labels)\n",
    "'''df_limit'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot_table을 이용한 user-item matrix 생성\n",
    "train_data_df_value = df_limit.copy()\n",
    "train_data_df_value['평균기온(°C)'] = train_data_df_value['평균기온(°C)'].astype('float32')\n",
    "UI_temp = train_data_df_value.pivot_table(index='userId', columns='옷 조합', values='평균기온(°C)', fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot_table을 이용한 user_\n",
    "UI_count = df_limit.pivot_table( index='userId', columns='옷 조합', aggfunc='size', fill_value=0)\n",
    "# 해당 user의 총 예제 개수로 각각의 row를 나눔\n",
    "UI_count_div = UI_count.div(UI_count.sum(axis=1), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 2, 4, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1,\n",
       "       1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 9, 1, 1, 1,\n",
       "       3, 1, 1, 2, 1, 1, 1, 1, 3, 1, 1, 1, 2, 1, 1, 1, 2, 4, 4, 2, 3, 2,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 2, 1, 1, 1, 1, 2, 2, 1, 1,\n",
       "       1, 3, 5, 5, 1, 6, 1, 1, 1, 2, 1, 1, 2, 3, 1, 1, 1, 1, 1, 2, 1, 1,\n",
       "       1, 1, 1, 1, 3, 2, 2, 2, 1, 1, 5, 3, 1, 1, 2, 2, 1, 1, 2, 2, 4, 1,\n",
       "       2, 1, 1, 3, 1, 1, 2, 1, 3, 1, 1, 1, 1, 1, 2, 2, 1, 2, 1, 1, 2, 1,\n",
       "       2, 1, 1, 1, 3, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 2, 1, 1, 1, 1,\n",
       "       1, 2, 1, 1, 2, 1, 1, 1, 1, 2, 2, 1, 6, 3, 4, 2, 1, 1, 2, 1, 2, 6,\n",
       "       2, 4, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 2, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 3, 1, 2, 1, 2, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 3, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1,\n",
       "       2, 5, 1, 1, 1, 2, 1, 1, 1, 1, 1, 5, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2,\n",
       "       1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 5, 3,\n",
       "       1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 2, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 3, 1, 1, 2, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1,\n",
       "       1, 1, 2, 1, 1, 1, 1, 2, 3, 4, 1, 1, 1, 1, 2, 2, 1, 1, 2, 1, 5, 1,\n",
       "       5, 3, 1, 1, 1, 4, 1, 5, 3, 3, 1, 1, 1, 2, 1, 5, 2, 4, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 2, 1,\n",
       "       1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1,\n",
       "       3, 2, 1, 1, 1, 2, 1, 5, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 2, 2, 3, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 4, 5, 1, 2, 1, 3, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 3, 2, 2, 1, 1, 1, 3, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# user-item matrix에 기록된 값이 존재하는 경우 1, 아닌 경우 0으로 변환하여 R_df에 기록\n",
    "R_df = UI_temp.map(lambda x: 1 if x != 0 else 0)\n",
    "R_np = np.array(R_df)\n",
    "R_np.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 열의 합이 2 이상(여러 유저가 해당 옷 조합을 선택한 경우)인 열을 찾음\n",
    "columns_with_sum_over_2 = R_df.columns[R_df.sum() >= 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(696, 14)\n"
     ]
    }
   ],
   "source": [
    "# CF를 위한 초기값 설정\n",
    "Y = np.array(UI_temp) \n",
    "Y = Y.T\n",
    "count = np.array(UI_count_div)\n",
    "count = count.T\n",
    "print(Y.shape)\n",
    "R = Y != 0 \n",
    "n_u = Y.shape[1]\n",
    "n_o = Y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기록이 존재하는 값의 평균을 구함\n",
    "o_sum = Y.sum(axis=1)\n",
    "o_count = R.sum(axis=1)\n",
    "o_mean = o_sum / o_count\n",
    "o_mean = o_mean.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_stand = Y - (o_mean * R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cofi_cost_func_v(O, U, b, Y, R, lambda_):\n",
    "    j = (tf.linalg.matmul(O, tf.transpose(U)) + b - Y )*R\n",
    "    J = 0.5 * tf.reduce_sum(j**2) + (lambda_/2) * (tf.reduce_sum(O**2) + tf.reduce_sum(U**2))\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user, outfit의 수\n",
    "n_o, n_u = Y.shape\n",
    "\n",
    "\n",
    "# (U,O)를 초기화하고 tf.Variable로 등록하여 추적\n",
    "tf.random.set_seed(1234) # for consistent results\n",
    "U = tf.Variable(tf.random.normal((n_u,  num_features),dtype=tf.float64),  name='U')\n",
    "O = tf.Variable(tf.random.normal((n_o, num_features),dtype=tf.float64),  name='O')\n",
    "b = tf.Variable(tf.random.normal((1,          n_u),   dtype=tf.float64),  name='b')\n",
    "\n",
    "# optimizer 초기화\n",
    "optimizer = keras.optimizers.Adam(learning_rate = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "J = cofi_cost_func_v(O, U, b, Y_stand, R, 1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost (with regularization): 32090.62\n"
     ]
    }
   ],
   "source": [
    "print(f\"Cost (with regularization): {J:0.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UI_temp.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'train_loss', 'epoch': 1, 'value': 26744.071991831097}\n",
      "{'type': 'train_loss', 'epoch': 20, 'value': 2202.8357580605716}\n",
      "{'type': 'train_loss', 'epoch': 40, 'value': 450.7418904770724}\n",
      "{'type': 'train_loss', 'epoch': 60, 'value': 143.0457811348213}\n",
      "{'type': 'train_loss', 'epoch': 80, 'value': 81.39842090839588}\n",
      "{'type': 'train_loss', 'epoch': 100, 'value': 66.14334859134937}\n",
      "{'type': 'train_loss', 'epoch': 120, 'value': 61.05975636393285}\n",
      "{'type': 'train_loss', 'epoch': 140, 'value': 58.900086584933966}\n"
     ]
    }
   ],
   "source": [
    "for iter in range(iterations):\n",
    "    # TensorFlow의 GradientTape 사용\n",
    "    # 연산을 기록하여 cost에 대한 gradient를 자동으로 계산\n",
    "    with tf.GradientTape() as tape:\n",
    "\n",
    "        # cost 계산 (forward pass included in cost)\n",
    "        cost_value = cofi_cost_func_v(O, U, b, Y_stand, R, lambda_)\n",
    "\n",
    "    # GradientTape를 통해 자동 미분\n",
    "    # loss에 대한 trainable parameter의 gradient를 계산\n",
    "    grads = tape.gradient( cost_value, [O,U,b] )\n",
    "\n",
    "    # optimizer를 사용하여 trainable parameter를 업데이트\n",
    "    optimizer.apply_gradients( zip(grads, [O,U,b]) )\n",
    "\n",
    "    # Log periodically.\n",
    "    if (iter + 1) % 20 == 0 or iter == 0:\n",
    "        train_loss = cost_value.numpy()\n",
    "        print({'type': 'train_loss', 'epoch': iter + 1, 'value': train_loss})\n",
    "\n",
    "        val_loss = cofi_cost_func_v(O, U, b, Y, R, lambda_).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# U의 값을 csv 파일로 저장\n",
    "df_U = pd.DataFrame(U.numpy())\n",
    "df_U.to_csv('../data/similarity/User_latent_factors.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_dictionary = {\n",
    "    \"반팔 티\": 1,\n",
    "    \"긴팔 티\": 2,\n",
    "    \"민소매 티\": 3,\n",
    "    \"반팔 니트\": 4,\n",
    "    \"니트\": 5,\n",
    "    \"후드티\": 6,\n",
    "    \"맨투맨\": 7,\n",
    "    \"반팔 셔츠/블라우스\": 8,\n",
    "    \"셔츠/블라우스\": 9,\n",
    "    \"점프슈트\": 10,\n",
    "    \"미니/미디원피스\": 11,\n",
    "    \"롱원피스\": 12,\n",
    "    \"반바지\": 13,\n",
    "    \"데님팬츠\": 14,\n",
    "    \"면바지\": 15,\n",
    "    \"슬랙스\": 16,\n",
    "    \"트레이닝/조거 팬츠\": 17,\n",
    "    \"카고바지\": 18,\n",
    "    \"레깅스\": 19,\n",
    "    \"가죽 바지\": 20,\n",
    "    \"나일론 팬츠\": 21,\n",
    "    \"미니/미디스커트\": 22,\n",
    "    \"롱스커트\": 23,\n",
    "    \"집업\": 24,\n",
    "    \"재킷\": 25,\n",
    "    \"바람막이\": 26,\n",
    "    \"점퍼\": 27,\n",
    "    \"가디건\": 28,\n",
    "    \"코트\": 29,\n",
    "    \"조끼\": 30,\n",
    "    \"패딩조끼\": 31,\n",
    "    \"패딩\": 32,\n",
    "    \"롱패딩\": 33,\n",
    "    \"운동화\": 34,\n",
    "    \"스니커즈/캔버스\": 35,\n",
    "    \"구두/로퍼\": 36,\n",
    "    \"힐\": 37,\n",
    "    \"샌들/슬리퍼\": 38,\n",
    "    \"레더부츠\": 39,\n",
    "    \"어그부츠\": 40,\n",
    "    \"레인부츠\": 41,\n",
    "    \"패딩슈즈\": 42,\n",
    "    \"비니\": 43,\n",
    "    \"털 모자\": 44,\n",
    "    \"기타 모자\": 45,\n",
    "    \"마스크\": 46,\n",
    "    \"머플러\": 47,\n",
    "    \"스카프\": 48,\n",
    "    \"장갑\": 49,\n",
    "    \"양말\": 50,\n",
    "    \"장목양말\": 51,\n",
    "    \"니삭스\": 52,\n",
    "    \"스타킹\": 53,\n",
    "    \"상의 없음\": 54,\n",
    "    \"아우터 없음\": 55,\n",
    "    \"하의 없음\": 56,\n",
    "    \"신발 없음\": 57,\n",
    "    \"액세서리 없음\": 58\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_id(item_dictionary, predict) :\n",
    "    predict_result = []\n",
    "    for i in predict:\n",
    "        items = i.split(', ')\n",
    "        predict_id = []\n",
    "        for j in items:\n",
    "            # 만약 items에 '없음'이라는 문자가 포함되면 continue\n",
    "            if '없음' in j:\n",
    "                continue\n",
    "            predict_id.append(item_dictionary[j])\n",
    "        # predict_id를 sort\n",
    "        predict_id.sort()\n",
    "        predict_result.append(predict_id)\n",
    "    return predict_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_id(item_dictionary, columns) :\n",
    "    columns_id = []\n",
    "    for i in columns:\n",
    "        items = i.split(', ')\n",
    "        column_id = []\n",
    "        for j in items:\n",
    "            # 만약 items에 '없음'이라는 문자가 포함되면 continue\n",
    "            if '없음' in j:\n",
    "                continue\n",
    "            column_id.append(item_dictionary[j])\n",
    "        # predict_id를 sort\n",
    "        column_id.sort()\n",
    "        # colums_id를 문자열로 변환\n",
    "        column_id = ', '.join(map(str, column_id))\n",
    "        columns_id.append(column_id)\n",
    "    return columns_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(O, U, b, o_mean, count, count_weight, UI_temp, labels, item_dictionary) :\n",
    "    # 예측을 수행하기 위해 모든 user-item에 대한 예측값을 계산\n",
    "    p = np.matmul(O.numpy(), np.transpose(U.numpy())) + b.numpy()\n",
    "    # user_category_not_valid에 해당하지 않는 경우에 대해 precision, recall, f1_score 계산\n",
    "    # 평균을 위한 초기화\n",
    "    precision_m, recall_m, f1_score_m, count_m = 0, 0, 0, 0\n",
    "    for i in range(UI_temp.shape[0]):\n",
    "        for category in labels:\n",
    "            \n",
    "            # 실제 온도\n",
    "            # 평균을 적용하고 temp를 빼서 값이 작을수록 실제 온도에 가깝도록 함. 이 때 각 user-item의 사용 횟수를 가중하여 많이 사용한 item이 추천되도록 함\n",
    "            pm = np.power(p + o_mean - category, 2)  -count * count_weight\n",
    "            my_predictions = pm[:,i]\n",
    "\n",
    "            # sort predictions\n",
    "            ix = tf.argsort(my_predictions, direction='ASCENDING')\n",
    "\n",
    "            df_predict = UI_temp[UI_temp.columns[ix[0:3]]].copy()\n",
    "            # df_predict의 columns와 test_data_df의 '옷 조합' column을 비교하여 일치하는 경우의 개수를 계산\n",
    "            predict = df_predict.columns.astype(str)\n",
    "            \n",
    "            predict_id = to_id(item_dictionary, predict)\n",
    "            \n",
    "            thick = []\n",
    "            for k in predict_id:\n",
    "                thick_comb = []\n",
    "                for item in k:\n",
    "                    thick_comb.append('null')\n",
    "                thick.append(thick_comb)\n",
    "            \n",
    "            # user i에 대한 예측을 파일로 저장\n",
    "            os.makedirs(f'../data/predictions/CF/male/user_{i+1}', exist_ok=True)\n",
    "            # Save predictions to file in user's directory\n",
    "            with open(f'../data/predictions/CF/male/user_{i+1}/predictions_{category}.txt', 'w') as f:\n",
    "                '''for item in predict:\n",
    "                    f.write(\"%s\\n\" % item)'''\n",
    "                for item in predict_id:\n",
    "                    f.write(\"%s\\n\" % item)   \n",
    "                for item in thick:\n",
    "                    f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(O, U, b, o_mean, count, count_weight, UI_temp, labels, item_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['null', 'null', 'null', 'null', 'null'],\n",
       " ['null', 'null', 'null', 'null'],\n",
       " ['null', 'null', 'null', 'null']]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thick = []\n",
    "for i in predict_id:\n",
    "    thick_comb = []\n",
    "    for j in i:\n",
    "        thick_comb.append('null')\n",
    "    thick.append(thick_comb)\n",
    "thick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def satis(O, U, b, o_mean):\n",
    "    p = np.matmul(O.numpy(), np.transpose(U.numpy())) + b.numpy()\n",
    "    p = p + o_mean\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = satis(O, U, b, o_mean)\n",
    "p_round = np.round(p, 1)\n",
    "UI_satis = pd.DataFrame(p_round, columns=UI_temp.index, index=UI_temp.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UI_satis의 각 index를 to_id 함수를 이용하여 id로 변환\n",
    "UI_satis_id = UI_satis.copy()\n",
    "UI_satis_id.index = index_id(item_dictionary, UI_satis_id.index.astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      옷 id  예측값\n",
      "0    2, 17, 28, 36, 45, 51  4.0\n",
      "1    2, 17, 28, 29, 36, 45  5.0\n",
      "2        1, 14, 28, 36, 45  6.0\n",
      "3            2, 14, 28, 36  5.0\n",
      "4        2, 14, 28, 29, 36  3.0\n",
      "..                     ...  ...\n",
      "691          6, 18, 25, 35  3.0\n",
      "692          6, 17, 25, 35  4.0\n",
      "693          6, 17, 27, 35  3.0\n",
      "694              6, 18, 34  4.0\n",
      "695          6, 18, 32, 34  0.9\n",
      "\n",
      "[696 rows x 2 columns]\n",
      "                      옷 id  예측값\n",
      "0    2, 17, 28, 36, 45, 51  4.0\n",
      "1    2, 17, 28, 29, 36, 45  5.0\n",
      "2        1, 14, 28, 36, 45  6.0\n",
      "3            2, 14, 28, 36  5.0\n",
      "4        2, 14, 28, 29, 36  3.0\n",
      "..                     ...  ...\n",
      "691          6, 18, 25, 35  3.0\n",
      "692          6, 17, 25, 35  4.0\n",
      "693          6, 17, 27, 35  3.0\n",
      "694              6, 18, 34  4.0\n",
      "695          6, 18, 32, 34  1.0\n",
      "\n",
      "[696 rows x 2 columns]\n",
      "                      옷 id  예측값\n",
      "0    2, 17, 28, 36, 45, 51  4.0\n",
      "1    2, 17, 28, 29, 36, 45  5.0\n",
      "2        1, 14, 28, 36, 45  6.1\n",
      "3            2, 14, 28, 36  5.1\n",
      "4        2, 14, 28, 29, 36  3.1\n",
      "..                     ...  ...\n",
      "691          6, 18, 25, 35  3.1\n",
      "692          6, 17, 25, 35  4.1\n",
      "693          6, 17, 27, 35  3.1\n",
      "694              6, 18, 34  4.1\n",
      "695          6, 18, 32, 34  1.1\n",
      "\n",
      "[696 rows x 2 columns]\n",
      "                      옷 id  예측값\n",
      "0    2, 17, 28, 36, 45, 51  3.8\n",
      "1    2, 17, 28, 29, 36, 45  4.8\n",
      "2        1, 14, 28, 36, 45  5.8\n",
      "3            2, 14, 28, 36  4.9\n",
      "4        2, 14, 28, 29, 36  2.8\n",
      "..                     ...  ...\n",
      "691          6, 18, 25, 35  2.8\n",
      "692          6, 17, 25, 35  3.9\n",
      "693          6, 17, 27, 35  2.8\n",
      "694              6, 18, 34  3.8\n",
      "695          6, 18, 32, 34  0.8\n",
      "\n",
      "[696 rows x 2 columns]\n",
      "                      옷 id  예측값\n",
      "0    2, 17, 28, 36, 45, 51  4.0\n",
      "1    2, 17, 28, 29, 36, 45  5.0\n",
      "2        1, 14, 28, 36, 45  6.0\n",
      "3            2, 14, 28, 36  5.0\n",
      "4        2, 14, 28, 29, 36  3.0\n",
      "..                     ...  ...\n",
      "691          6, 18, 25, 35  3.0\n",
      "692          6, 17, 25, 35  4.0\n",
      "693          6, 17, 27, 35  3.0\n",
      "694              6, 18, 34  4.0\n",
      "695          6, 18, 32, 34  1.0\n",
      "\n",
      "[696 rows x 2 columns]\n",
      "                      옷 id  예측값\n",
      "0    2, 17, 28, 36, 45, 51  3.9\n",
      "1    2, 17, 28, 29, 36, 45  4.9\n",
      "2        1, 14, 28, 36, 45  5.9\n",
      "3            2, 14, 28, 36  4.9\n",
      "4        2, 14, 28, 29, 36  2.9\n",
      "..                     ...  ...\n",
      "691          6, 18, 25, 35  2.9\n",
      "692          6, 17, 25, 35  3.9\n",
      "693          6, 17, 27, 35  2.9\n",
      "694              6, 18, 34  3.9\n",
      "695          6, 18, 32, 34  0.9\n",
      "\n",
      "[696 rows x 2 columns]\n",
      "                      옷 id  예측값\n",
      "0    2, 17, 28, 36, 45, 51  3.9\n",
      "1    2, 17, 28, 29, 36, 45  4.9\n",
      "2        1, 14, 28, 36, 45  5.9\n",
      "3            2, 14, 28, 36  4.9\n",
      "4        2, 14, 28, 29, 36  2.9\n",
      "..                     ...  ...\n",
      "691          6, 18, 25, 35  2.9\n",
      "692          6, 17, 25, 35  3.9\n",
      "693          6, 17, 27, 35  2.9\n",
      "694              6, 18, 34  3.9\n",
      "695          6, 18, 32, 34  0.9\n",
      "\n",
      "[696 rows x 2 columns]\n",
      "                      옷 id  예측값\n",
      "0    2, 17, 28, 36, 45, 51  4.1\n",
      "1    2, 17, 28, 29, 36, 45  5.1\n",
      "2        1, 14, 28, 36, 45  6.1\n",
      "3            2, 14, 28, 36  5.1\n",
      "4        2, 14, 28, 29, 36  3.1\n",
      "..                     ...  ...\n",
      "691          6, 18, 25, 35  3.1\n",
      "692          6, 17, 25, 35  4.1\n",
      "693          6, 17, 27, 35  3.1\n",
      "694              6, 18, 34  4.1\n",
      "695          6, 18, 32, 34  1.1\n",
      "\n",
      "[696 rows x 2 columns]\n",
      "                      옷 id  예측값\n",
      "0    2, 17, 28, 36, 45, 51  3.9\n",
      "1    2, 17, 28, 29, 36, 45  4.9\n",
      "2        1, 14, 28, 36, 45  6.0\n",
      "3            2, 14, 28, 36  5.0\n",
      "4        2, 14, 28, 29, 36  3.0\n",
      "..                     ...  ...\n",
      "691          6, 18, 25, 35  2.9\n",
      "692          6, 17, 25, 35  4.0\n",
      "693          6, 17, 27, 35  3.0\n",
      "694              6, 18, 34  3.9\n",
      "695          6, 18, 32, 34  1.0\n",
      "\n",
      "[696 rows x 2 columns]\n",
      "                      옷 id  예측값\n",
      "0    2, 17, 28, 36, 45, 51  3.9\n",
      "1    2, 17, 28, 29, 36, 45  4.9\n",
      "2        1, 14, 28, 36, 45  5.9\n",
      "3            2, 14, 28, 36  5.0\n",
      "4        2, 14, 28, 29, 36  2.9\n",
      "..                     ...  ...\n",
      "691          6, 18, 25, 35  2.9\n",
      "692          6, 17, 25, 35  4.0\n",
      "693          6, 17, 27, 35  2.9\n",
      "694              6, 18, 34  3.9\n",
      "695          6, 18, 32, 34  0.9\n",
      "\n",
      "[696 rows x 2 columns]\n",
      "                      옷 id  예측값\n",
      "0    2, 17, 28, 36, 45, 51  4.0\n",
      "1    2, 17, 28, 29, 36, 45  5.0\n",
      "2        1, 14, 28, 36, 45  6.0\n",
      "3            2, 14, 28, 36  5.0\n",
      "4        2, 14, 28, 29, 36  3.0\n",
      "..                     ...  ...\n",
      "691          6, 18, 25, 35  3.0\n",
      "692          6, 17, 25, 35  4.0\n",
      "693          6, 17, 27, 35  3.0\n",
      "694              6, 18, 34  4.0\n",
      "695          6, 18, 32, 34  1.0\n",
      "\n",
      "[696 rows x 2 columns]\n",
      "                      옷 id  예측값\n",
      "0    2, 17, 28, 36, 45, 51  4.0\n",
      "1    2, 17, 28, 29, 36, 45  5.0\n",
      "2        1, 14, 28, 36, 45  6.0\n",
      "3            2, 14, 28, 36  5.0\n",
      "4        2, 14, 28, 29, 36  3.0\n",
      "..                     ...  ...\n",
      "691          6, 18, 25, 35  3.0\n",
      "692          6, 17, 25, 35  4.0\n",
      "693          6, 17, 27, 35  3.0\n",
      "694              6, 18, 34  4.0\n",
      "695          6, 18, 32, 34  1.0\n",
      "\n",
      "[696 rows x 2 columns]\n",
      "                      옷 id  예측값\n",
      "0    2, 17, 28, 36, 45, 51  4.1\n",
      "1    2, 17, 28, 29, 36, 45  5.1\n",
      "2        1, 14, 28, 36, 45  6.1\n",
      "3            2, 14, 28, 36  5.1\n",
      "4        2, 14, 28, 29, 36  3.1\n",
      "..                     ...  ...\n",
      "691          6, 18, 25, 35  3.1\n",
      "692          6, 17, 25, 35  4.1\n",
      "693          6, 17, 27, 35  3.1\n",
      "694              6, 18, 34  4.1\n",
      "695          6, 18, 32, 34  1.2\n",
      "\n",
      "[696 rows x 2 columns]\n",
      "                      옷 id  예측값\n",
      "0    2, 17, 28, 36, 45, 51  4.0\n",
      "1    2, 17, 28, 29, 36, 45  5.0\n",
      "2        1, 14, 28, 36, 45  5.9\n",
      "3            2, 14, 28, 36  4.9\n",
      "4        2, 14, 28, 29, 36  2.9\n",
      "..                     ...  ...\n",
      "691          6, 18, 25, 35  2.9\n",
      "692          6, 17, 25, 35  3.9\n",
      "693          6, 17, 27, 35  2.9\n",
      "694              6, 18, 34  3.9\n",
      "695          6, 18, 32, 34  0.9\n",
      "\n",
      "[696 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "for i in range(UI_satis_id.shape[1]):\n",
    "    user_id = UI_satis_id.columns[i]\n",
    "    temp = UI_satis_id.copy()\n",
    "    temp = temp[[user_id]]\n",
    "    temp.columns = ['예측값']\n",
    "    temp.reset_index(inplace=True)\n",
    "    temp.columns = ['옷 id', '예측값']\n",
    "    print(temp)\n",
    "    # UI_satis의 해당하는 user_id column의 각 값에 대해 j값을 뺌\n",
    "    # user i에 대한 예측을 파일로 저장\n",
    "    os.makedirs(f'../data/satisfaction/CF/male/user_{i+1}', exist_ok=True)\n",
    "    temp.to_csv(f'../data/satisfaction/CF/male/user_{user_id}/satifaction.csv', index=False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ondoset",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
