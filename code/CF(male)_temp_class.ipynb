{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-10 19:44:53.555061: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-10 19:44:53.602528: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-10 19:44:53.602586: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-10 19:44:53.605388: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CountVectorizer\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n",
      "File \u001b[0;32m~/anaconda3/envs/ondoset/lib/python3.9/site-packages/tensorflow/__init__.py:48\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf2 \u001b[38;5;28;01mas\u001b[39;00m _tf2\n\u001b[1;32m     46\u001b[0m _tf2\u001b[38;5;241m.\u001b[39menable()\n\u001b[0;32m---> 48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __operators__\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m audio\n",
      "File \u001b[0;32m~/anaconda3/envs/ondoset/lib/python3.9/site-packages/tensorflow/_api/v2/__internal__/__init__.py:8\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__ namespace\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m autograph\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m decorator\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dispatch\n",
      "File \u001b[0;32m~/anaconda3/envs/ondoset/lib/python3.9/site-packages/tensorflow/_api/v2/__internal__/autograph/__init__.py:8\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__.autograph namespace\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mag_ctx\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m control_status_ctx \u001b[38;5;66;03m# line: 34\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimpl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf_convert \u001b[38;5;66;03m# line: 493\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ondoset/lib/python3.9/site-packages/tensorflow/python/autograph/core/ag_ctx.py:21\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01minspect\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mthreading\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ag_logging\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtf_export\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf_export\n\u001b[1;32m     25\u001b[0m stacks \u001b[38;5;241m=\u001b[39m threading\u001b[38;5;241m.\u001b[39mlocal()\n",
      "File \u001b[0;32m~/anaconda3/envs/ondoset/lib/python3.9/site-packages/tensorflow/python/autograph/utils/__init__.py:17\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Utility module that contains APIs usable in the generated code.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontext_managers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m control_dependency_on_returns\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmisc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m alias_tensors\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensor_list\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dynamic_list_append\n",
      "File \u001b[0;32m~/anaconda3/envs/ondoset/lib/python3.9/site-packages/tensorflow/python/autograph/utils/context_managers.py:19\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Various context managers.\"\"\"\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcontextlib\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ops\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tensor_array_ops\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcontrol_dependency_on_returns\u001b[39m(return_value):\n",
      "File \u001b[0;32m~/anaconda3/envs/ondoset/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:40\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config_pb2\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# pywrap_tensorflow must be imported first to avoid protobuf issues.\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# (b/143110113)\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# pylint: disable=invalid-import-order,g-bad-import-order,unused-import\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pywrap_tensorflow\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pywrap_tfe\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# pylint: enable=invalid-import-order,g-bad-import-order,unused-import\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ondoset/lib/python3.9/site-packages/tensorflow/python/pywrap_tensorflow.py:34\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplatform\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m self_check\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# TODO(mdan): Cleanup antipattern: import for side effects.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Perform pre-load sanity checks in order to produce a more actionable error.\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m \u001b[43mself_check\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreload_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# pylint: disable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     39\u001b[0m   \u001b[38;5;66;03m# This import is expected to fail if there is an explicit shared object\u001b[39;00m\n\u001b[1;32m     40\u001b[0m   \u001b[38;5;66;03m# dependency (with_framework_lib=true), since we do not need RTLD_GLOBAL.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ondoset/lib/python3.9/site-packages/tensorflow/python/platform/self_check.py:63\u001b[0m, in \u001b[0;36mpreload_check\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m     51\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not find the DLL(s) \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m. TensorFlow requires that these DLLs \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     52\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbe installed in a directory that is named in your \u001b[39m\u001b[38;5;132;01m%%\u001b[39;00m\u001b[38;5;124mPATH\u001b[39m\u001b[38;5;132;01m%%\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     56\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://support.microsoft.com/help/2977003/the-latest-supported-visual-c-downloads\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     57\u001b[0m           \u001b[38;5;241m%\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(missing))\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m   \u001b[38;5;66;03m# Load a library that performs CPU feature guard checking.  Doing this here\u001b[39;00m\n\u001b[1;32m     60\u001b[0m   \u001b[38;5;66;03m# as a preload check makes it more likely that we detect any CPU feature\u001b[39;00m\n\u001b[1;32m     61\u001b[0m   \u001b[38;5;66;03m# incompatibilities before we trigger them (which would typically result in\u001b[39;00m\n\u001b[1;32m     62\u001b[0m   \u001b[38;5;66;03m# SIGILL).\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m   \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplatform\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _pywrap_cpu_feature_guard\n\u001b[1;32m     64\u001b[0m   _pywrap_cpu_feature_guard\u001b[38;5;241m.\u001b[39mInfoAboutUnusedCPUFeatures()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>상의</th>\n",
       "      <th>아우터</th>\n",
       "      <th>하의</th>\n",
       "      <th>신발</th>\n",
       "      <th>액세서리</th>\n",
       "      <th>작성일</th>\n",
       "      <th>평균기온(°C)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>반팔 티, 셔츠/블라우스</td>\n",
       "      <td>재킷</td>\n",
       "      <td>반바지</td>\n",
       "      <td>구두/로퍼</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-04-24</td>\n",
       "      <td>13.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>반팔 티</td>\n",
       "      <td>재킷</td>\n",
       "      <td>반바지</td>\n",
       "      <td>운동화</td>\n",
       "      <td>기타 모자</td>\n",
       "      <td>2024-04-19</td>\n",
       "      <td>17.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>반팔 티</td>\n",
       "      <td>재킷</td>\n",
       "      <td>반바지</td>\n",
       "      <td>구두/로퍼</td>\n",
       "      <td>장목양말</td>\n",
       "      <td>2024-04-15</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>반팔 티</td>\n",
       "      <td>NaN</td>\n",
       "      <td>나일론 팬츠</td>\n",
       "      <td>구두/로퍼</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-04-09</td>\n",
       "      <td>15.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>반팔 티</td>\n",
       "      <td>집업</td>\n",
       "      <td>면바지</td>\n",
       "      <td>구두/로퍼</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-04-05</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>14</td>\n",
       "      <td>반팔 티</td>\n",
       "      <td>NaN</td>\n",
       "      <td>반바지</td>\n",
       "      <td>운동화</td>\n",
       "      <td>기타 모자, 장목양말</td>\n",
       "      <td>2024-04-23</td>\n",
       "      <td>17.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>14</td>\n",
       "      <td>반팔 티</td>\n",
       "      <td>NaN</td>\n",
       "      <td>카고바지</td>\n",
       "      <td>운동화</td>\n",
       "      <td>기타 모자</td>\n",
       "      <td>2024-04-24</td>\n",
       "      <td>13.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>14</td>\n",
       "      <td>반팔 티</td>\n",
       "      <td>집업</td>\n",
       "      <td>나일론 팬츠</td>\n",
       "      <td>스니커즈/캔버스</td>\n",
       "      <td>기타 모자</td>\n",
       "      <td>2024-04-25</td>\n",
       "      <td>14.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>14</td>\n",
       "      <td>반팔 티, 셔츠/블라우스</td>\n",
       "      <td>NaN</td>\n",
       "      <td>반바지</td>\n",
       "      <td>구두/로퍼</td>\n",
       "      <td>장목양말</td>\n",
       "      <td>2024-04-26</td>\n",
       "      <td>17.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>14</td>\n",
       "      <td>반팔 티</td>\n",
       "      <td>NaN</td>\n",
       "      <td>데님팬츠</td>\n",
       "      <td>운동화</td>\n",
       "      <td>기타 모자</td>\n",
       "      <td>2024-04-27</td>\n",
       "      <td>18.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1338 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      userId             상의  아우터      하의        신발         액세서리        작성일  \\\n",
       "0          1  반팔 티, 셔츠/블라우스   재킷     반바지     구두/로퍼          NaN 2024-04-24   \n",
       "1          1           반팔 티   재킷     반바지       운동화        기타 모자 2024-04-19   \n",
       "2          1           반팔 티   재킷     반바지     구두/로퍼         장목양말 2024-04-15   \n",
       "3          1           반팔 티  NaN  나일론 팬츠     구두/로퍼          NaN 2024-04-09   \n",
       "4          1           반팔 티   집업     면바지     구두/로퍼          NaN 2024-04-05   \n",
       "...      ...            ...  ...     ...       ...          ...        ...   \n",
       "1333      14           반팔 티  NaN     반바지       운동화  기타 모자, 장목양말 2024-04-23   \n",
       "1334      14           반팔 티  NaN    카고바지       운동화        기타 모자 2024-04-24   \n",
       "1335      14           반팔 티   집업  나일론 팬츠  스니커즈/캔버스        기타 모자 2024-04-25   \n",
       "1336      14  반팔 티, 셔츠/블라우스  NaN     반바지     구두/로퍼         장목양말 2024-04-26   \n",
       "1337      14           반팔 티  NaN    데님팬츠       운동화        기타 모자 2024-04-27   \n",
       "\n",
       "      평균기온(°C)  \n",
       "0         13.2  \n",
       "1         17.6  \n",
       "2         16.0  \n",
       "3         15.3  \n",
       "4         14.0  \n",
       "...        ...  \n",
       "1333      17.3  \n",
       "1334      13.2  \n",
       "1335      14.4  \n",
       "1336      17.8  \n",
       "1337      18.2  \n",
       "\n",
       "[1338 rows x 8 columns]"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# csv 파일을 dataframe으로 변환\n",
    "df_outfit = pd.read_csv('../data/outfit(male)/outfit(male).csv')\n",
    "df_weather = pd.read_csv('../data/2022-08-01_to_2024-04-30.csv', encoding='cp949')\n",
    "# 필요한 columns만 추출\n",
    "df_outfit = df_outfit[['userId', '상의', '아우터', '하의', '신발', '액세서리', '작성일']].copy()\n",
    "df_temp = df_weather[['일시', '평균기온(°C)']].copy()\n",
    "\n",
    "# '작성일'과 '일시' 열을 datetime 형식으로 변환\n",
    "df_outfit['작성일'] = pd.to_datetime(df_outfit['작성일'], format='%Y년 %m월 %d일')\n",
    "df_temp['일시'] = pd.to_datetime(df_temp['일시'])\n",
    "\n",
    "# 두 dataframe을 날짜를 기준으로 병합\n",
    "df_merged = pd.merge(df_outfit, df_temp, left_on='작성일', right_on='일시').drop('일시', axis=1)\n",
    "\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '상의', '아우터', '하의', '신발', '엑세서리' 열의 결측값을 '~ 없음'으로 대체\n",
    "columns = ['상의', '아우터', '하의', '신발', '액세서리']\n",
    "df_notnull = df_merged.copy()\n",
    "for column in columns:\n",
    "    df_notnull[column] = df_merged[column].fillna(column + ' 없음')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"df_notnull[df_notnull['아우터'].str.contains('재킷 2')]\""
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''df_notnull[df_notnull['아우터'].str.contains('재킷 2')]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"df_dup[df_dup['아우터'].str.contains('니트')]\""
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''df_dup[df_dup['아우터'].str.contains('니트')]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2가 붙은 단어를 두 번 반복하는 함수\n",
    "def duplicate_word(text):\n",
    "    words = text.split(', ')\n",
    "    for i, word in enumerate(words):\n",
    "        if '2' in word:\n",
    "            words[i] = word.replace('2', '') + ', ' + word.replace('2', '')\n",
    "    return ', '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2가 붙은 단어를 두 번 반복한 dataframe df_dup 생성\n",
    "df_dup = df_notnull.copy()\n",
    "for column in columns:\n",
    "    df_dup[columns] = df_notnull[columns].map(duplicate_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['userId', '상의', '아우터', '하의', '신발', '액세서리', '작성일', '평균기온(°C)'], dtype='object')"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dup.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 옷의 조합 컬럼 생성 (상의, 아우터, 하의, 신발, 엑세서리의 각 값들을 하나의 문자열로 조합하여 하나의 컬럼으로 만듦)\n",
    "df_combination = df_dup.copy()\n",
    "df_combination['옷 조합'] = df_dup['상의'] + ', ' + df_dup['아우터'] + ', ' + df_dup['하의'] + ', ' + df_dup['신발'] + ', ' + df_dup['액세서리']\n",
    "df_combination.drop(columns=['상의', '아우터', '하의', '신발', '액세서리'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['userId', '작성일', '평균기온(°C)', '옷 조합'], dtype='object')"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combination.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"df_combination[df_combination['옷 조합'].str.contains('니트 , 니트')]\""
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''df_combination[df_combination['옷 조합'].str.contains('니트 , 니트')]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# 옷의 조합 컬럼의 공백 제거\\ndf_combination['옷 조합'] = df_combination['옷 조합'].str.replace(' ', '')\""
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# 옷의 조합 컬럼의 공백 제거\n",
    "df_combination['옷 조합'] = df_combination['옷 조합'].str.replace(' ', '')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ksy/anaconda3/envs/ondoset/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1338, 45)"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 쉼표를 기준으로 텍스트를 나누는 함수\n",
    "def comma_tokenizer(s):\n",
    "    return s.split(', ')\n",
    "\n",
    "vectorizer = CountVectorizer(tokenizer=comma_tokenizer)\n",
    "\n",
    "O = vectorizer.fit_transform(df_combination['옷 조합'])\n",
    "\n",
    "# multi-hot encoding된 데이터를 numpy array로 변환\n",
    "df_encoded = pd.DataFrame(O.toarray().tolist(), columns=vectorizer.get_feature_names_out())\n",
    "npa = np.array(df_encoded)\n",
    "npa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([86, 317, 430, 435, 560, 593, 633, 640, 793, 1039], dtype='int64')"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 값이 2 이상인 행의 인덱스\n",
    "rows_with_value_2 = df_encoded[(df_encoded >= 2).any(axis=1)]\n",
    "rows_with_value_2.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>니트</th>\n",
       "      <th>민소매 티</th>\n",
       "      <th>반팔 티</th>\n",
       "      <th>재킷</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1039</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      니트  민소매 티  반팔 티  재킷\n",
       "86     0      2     1   1\n",
       "317    2      0     0   0\n",
       "430    0      0     2   0\n",
       "435    0      0     2   0\n",
       "560    0      0     0   2\n",
       "593    0      0     2   0\n",
       "633    1      0     2   1\n",
       "640    0      0     1   2\n",
       "793    2      0     0   0\n",
       "1039   0      0     2   0"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 값이 2 이상인 열의 이름을 찾습니다.\n",
    "columns_with_value_over_2 = df_encoded.columns[(df_encoded >= 2).any()]\n",
    "\n",
    "# 특정 행에 대해 이를 기록합니다.\n",
    "record = df_encoded.loc[rows_with_value_2.index, columns_with_value_over_2]\n",
    "record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "1       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "2       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "3       [0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "4       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...\n",
       "                              ...                        \n",
       "1333    [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "1334    [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "1335    [0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "1336    [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "1337    [0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "Name: 옷 조합, Length: 1338, dtype: object"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numpy array를 list로 변환 후 clothes_combination 컬럼에 대입\n",
    "df_combination['옷 조합'] = npa.tolist()\n",
    "df_combination['옷 조합']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [구두/로퍼, 반바지, 반팔 티, 셔츠/블라우스, 액세서리 없음, 재킷]\n",
       "1                     [기타 모자, 반바지, 반팔 티, 운동화, 재킷]\n",
       "2                    [구두/로퍼, 반바지, 반팔 티, 장목양말, 재킷]\n",
       "3          [구두/로퍼, 나일론 팬츠, 반팔 티, 아우터 없음, 액세서리 없음]\n",
       "4                 [구두/로퍼, 면바지, 반팔 티, 액세서리 없음, 집업]\n",
       "                          ...                    \n",
       "1333        [기타 모자, 반바지, 반팔 티, 아우터 없음, 운동화, 장목양말]\n",
       "1334             [기타 모자, 반팔 티, 아우터 없음, 운동화, 카고바지]\n",
       "1335          [기타 모자, 나일론 팬츠, 반팔 티, 스니커즈/캔버스, 집업]\n",
       "1336    [구두/로퍼, 반바지, 반팔 티, 셔츠/블라우스, 아우터 없음, 장목양말]\n",
       "1337             [기타 모자, 데님팬츠, 반팔 티, 아우터 없음, 운동화]\n",
       "Name: 옷 조합, Length: 1338, dtype: object"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# multi-hot encoding된 데이터를 다시 텍스트로 변환\n",
    "df_combination['옷 조합'] = vectorizer.inverse_transform(npa)\n",
    "df_combination['옷 조합'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하나의 문자열로 변환\n",
    "df_combtest = df_combination.copy()\n",
    "df_combtest['옷 조합'] = df_combination['옷 조합'].apply(lambda x: ', '.join(map(str, x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi-hot encoding의 값이 2 이상인 경우, 해당 단어를 두 번 반복\n",
    "for i in record.index:\n",
    "    old_value = df_combtest.loc[i, '옷 조합']\n",
    "    for col in record.columns:\n",
    "        if record.loc[i, col] >= 2:\n",
    "            old_value = old_value.replace(col, col + ', ' + col)\n",
    "    df_combtest.loc[i, '옷 조합'] = old_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86      기타 모자, 데님팬츠, 민소매 티, 민소매 티, 반팔 티, 셔츠/블라우스, 스니커즈...\n",
       "317               니트, 니트, 데님팬츠, 스니커즈/캔버스, 아우터 없음, 액세서리 없음\n",
       "430           데님팬츠, 반팔 티, 반팔 티, 스니커즈/캔버스, 아우터 없음, 액세서리 없음\n",
       "435              면바지, 반팔 티, 반팔 티, 샌들/슬리퍼, 아우터 없음, 액세서리 없음\n",
       "560               구두/로퍼, 기타 모자, 데님팬츠, 셔츠/블라우스, 재킷, 재킷, 조끼\n",
       "593                    반바지, 반팔 티, 반팔 티, 아우터 없음, 운동화, 장목양말\n",
       "633               구두/로퍼, 니트, 면바지, 반팔 티, 반팔 티, 액세서리 없음, 재킷\n",
       "640                     구두/로퍼, 면바지, 반팔 티, 액세서리 없음, 재킷, 재킷\n",
       "793                      니트, 니트, 비니, 스니커즈/캔버스, 카고바지, 패딩조끼\n",
       "1039              반바지, 반팔 티, 반팔 티, 스니커즈/캔버스, 아우터 없음, 장목양말\n",
       "Name: 옷 조합, dtype: object"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combtest.loc[rows_with_value_2.index, '옷 조합']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>작성일</th>\n",
       "      <th>평균기온(°C)</th>\n",
       "      <th>옷 조합</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-04-24</td>\n",
       "      <td>13.2</td>\n",
       "      <td>구두/로퍼, 반바지, 반팔 티, 셔츠/블라우스, 액세서리 없음, 재킷</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-04-19</td>\n",
       "      <td>17.6</td>\n",
       "      <td>기타 모자, 반바지, 반팔 티, 운동화, 재킷</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-04-15</td>\n",
       "      <td>16.0</td>\n",
       "      <td>구두/로퍼, 반바지, 반팔 티, 장목양말, 재킷</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-04-09</td>\n",
       "      <td>15.3</td>\n",
       "      <td>구두/로퍼, 나일론 팬츠, 반팔 티, 아우터 없음, 액세서리 없음</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-04-05</td>\n",
       "      <td>14.0</td>\n",
       "      <td>구두/로퍼, 면바지, 반팔 티, 액세서리 없음, 집업</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>14</td>\n",
       "      <td>2024-04-23</td>\n",
       "      <td>17.3</td>\n",
       "      <td>기타 모자, 반바지, 반팔 티, 아우터 없음, 운동화, 장목양말</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>14</td>\n",
       "      <td>2024-04-24</td>\n",
       "      <td>13.2</td>\n",
       "      <td>기타 모자, 반팔 티, 아우터 없음, 운동화, 카고바지</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>14</td>\n",
       "      <td>2024-04-25</td>\n",
       "      <td>14.4</td>\n",
       "      <td>기타 모자, 나일론 팬츠, 반팔 티, 스니커즈/캔버스, 집업</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>14</td>\n",
       "      <td>2024-04-26</td>\n",
       "      <td>17.8</td>\n",
       "      <td>구두/로퍼, 반바지, 반팔 티, 셔츠/블라우스, 아우터 없음, 장목양말</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>14</td>\n",
       "      <td>2024-04-27</td>\n",
       "      <td>18.2</td>\n",
       "      <td>기타 모자, 데님팬츠, 반팔 티, 아우터 없음, 운동화</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1338 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      userId        작성일  평균기온(°C)                                     옷 조합\n",
       "0          1 2024-04-24      13.2   구두/로퍼, 반바지, 반팔 티, 셔츠/블라우스, 액세서리 없음, 재킷\n",
       "1          1 2024-04-19      17.6                기타 모자, 반바지, 반팔 티, 운동화, 재킷\n",
       "2          1 2024-04-15      16.0               구두/로퍼, 반바지, 반팔 티, 장목양말, 재킷\n",
       "3          1 2024-04-09      15.3     구두/로퍼, 나일론 팬츠, 반팔 티, 아우터 없음, 액세서리 없음\n",
       "4          1 2024-04-05      14.0            구두/로퍼, 면바지, 반팔 티, 액세서리 없음, 집업\n",
       "...      ...        ...       ...                                      ...\n",
       "1333      14 2024-04-23      17.3      기타 모자, 반바지, 반팔 티, 아우터 없음, 운동화, 장목양말\n",
       "1334      14 2024-04-24      13.2           기타 모자, 반팔 티, 아우터 없음, 운동화, 카고바지\n",
       "1335      14 2024-04-25      14.4        기타 모자, 나일론 팬츠, 반팔 티, 스니커즈/캔버스, 집업\n",
       "1336      14 2024-04-26      17.8  구두/로퍼, 반바지, 반팔 티, 셔츠/블라우스, 아우터 없음, 장목양말\n",
       "1337      14 2024-04-27      18.2           기타 모자, 데님팬츠, 반팔 티, 아우터 없음, 운동화\n",
       "\n",
       "[1338 rows x 4 columns]"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.9 -11.8\n"
     ]
    }
   ],
   "source": [
    "# 평균기온(°C) column의 최대값과 최솟값\n",
    "max_temp = df_combtest['평균기온(°C)'].max()\n",
    "min_temp = df_combtest['평균기온(°C)'].min()\n",
    "print(max_temp, min_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>작성일</th>\n",
       "      <th>평균기온(°C)</th>\n",
       "      <th>옷 조합</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-04-24</td>\n",
       "      <td>5.0</td>\n",
       "      <td>구두/로퍼, 반바지, 반팔 티, 셔츠/블라우스, 액세서리 없음, 재킷</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-04-19</td>\n",
       "      <td>6.0</td>\n",
       "      <td>기타 모자, 반바지, 반팔 티, 운동화, 재킷</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-04-15</td>\n",
       "      <td>6.0</td>\n",
       "      <td>구두/로퍼, 반바지, 반팔 티, 장목양말, 재킷</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-04-09</td>\n",
       "      <td>6.0</td>\n",
       "      <td>구두/로퍼, 나일론 팬츠, 반팔 티, 아우터 없음, 액세서리 없음</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-04-05</td>\n",
       "      <td>6.0</td>\n",
       "      <td>구두/로퍼, 면바지, 반팔 티, 액세서리 없음, 집업</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>14</td>\n",
       "      <td>2024-04-23</td>\n",
       "      <td>6.0</td>\n",
       "      <td>기타 모자, 반바지, 반팔 티, 아우터 없음, 운동화, 장목양말</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>14</td>\n",
       "      <td>2024-04-24</td>\n",
       "      <td>5.0</td>\n",
       "      <td>기타 모자, 반팔 티, 아우터 없음, 운동화, 카고바지</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>14</td>\n",
       "      <td>2024-04-25</td>\n",
       "      <td>6.0</td>\n",
       "      <td>기타 모자, 나일론 팬츠, 반팔 티, 스니커즈/캔버스, 집업</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>14</td>\n",
       "      <td>2024-04-26</td>\n",
       "      <td>6.0</td>\n",
       "      <td>구두/로퍼, 반바지, 반팔 티, 셔츠/블라우스, 아우터 없음, 장목양말</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>14</td>\n",
       "      <td>2024-04-27</td>\n",
       "      <td>6.0</td>\n",
       "      <td>기타 모자, 데님팬츠, 반팔 티, 아우터 없음, 운동화</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1338 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      userId        작성일 평균기온(°C)                                     옷 조합\n",
       "0          1 2024-04-24      5.0   구두/로퍼, 반바지, 반팔 티, 셔츠/블라우스, 액세서리 없음, 재킷\n",
       "1          1 2024-04-19      6.0                기타 모자, 반바지, 반팔 티, 운동화, 재킷\n",
       "2          1 2024-04-15      6.0               구두/로퍼, 반바지, 반팔 티, 장목양말, 재킷\n",
       "3          1 2024-04-09      6.0     구두/로퍼, 나일론 팬츠, 반팔 티, 아우터 없음, 액세서리 없음\n",
       "4          1 2024-04-05      6.0            구두/로퍼, 면바지, 반팔 티, 액세서리 없음, 집업\n",
       "...      ...        ...      ...                                      ...\n",
       "1333      14 2024-04-23      6.0      기타 모자, 반바지, 반팔 티, 아우터 없음, 운동화, 장목양말\n",
       "1334      14 2024-04-24      5.0           기타 모자, 반팔 티, 아우터 없음, 운동화, 카고바지\n",
       "1335      14 2024-04-25      6.0        기타 모자, 나일론 팬츠, 반팔 티, 스니커즈/캔버스, 집업\n",
       "1336      14 2024-04-26      6.0  구두/로퍼, 반바지, 반팔 티, 셔츠/블라우스, 아우터 없음, 장목양말\n",
       "1337      14 2024-04-27      6.0           기타 모자, 데님팬츠, 반팔 티, 아우터 없음, 운동화\n",
       "\n",
       "[1338 rows x 4 columns]"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_limit = df_combtest.copy()\n",
    "# 평균기온(°C) column을 5도 간격으로 범주화하여 0, 1, 2, ...로 변환\n",
    "df_limit['평균기온(°C)'] = pd.cut(df_limit['평균기온(°C)'],bins=np.round(np.arange(min_temp -5, max_temp+5, 5), 1), labels=np.arange(0, (max_temp-min_temp)//5+2))\n",
    "df_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_923/1967549491.py:3: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df_limit = df_limit.groupby('평균기온(°C)').filter(lambda x: len(x) > 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5.0, 6.0, 4.0, 3.0, 1.0, 7.0, 8.0, 9.0, 2.0]\n",
       "Categories (10, float64): [0.0 < 1.0 < 2.0 < 3.0 ... 6.0 < 7.0 < 8.0 < 9.0]"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 평균기온(°C) column의 각 class에 포함된 개수가 10개 이하라면 제외\n",
    "df_limit = df_limit.copy()\n",
    "df_limit = df_limit.groupby('평균기온(°C)').filter(lambda x: len(x) > 10)\n",
    "df_limit['평균기온(°C)'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_923/3554806506.py:2: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df_limit.groupby(['userId', '평균기온(°C)']).size()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "userId  평균기온(°C)\n",
       "1       0.0          0\n",
       "        1.0          2\n",
       "        2.0          0\n",
       "        3.0         14\n",
       "        4.0         21\n",
       "                    ..\n",
       "14      5.0         25\n",
       "        6.0         37\n",
       "        7.0         35\n",
       "        8.0         39\n",
       "        9.0         11\n",
       "Length: 140, dtype: int64"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 각 user의 온도 별 예제 개수\n",
    "df_limit.groupby(['userId', '평균기온(°C)']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: [3.0, 1.0, 7.0, 8.0, 9.0, 2.0], 2: [5.0, 4.0, 3.0, 1.0, 7.0, 9.0, 2.0], 3: [5.0, 1.0, 9.0, 2.0], 4: [5.0, 6.0, 4.0, 3.0, 1.0, 7.0, 8.0, 9.0, 2.0], 5: [5.0, 6.0, 4.0, 3.0, 1.0, 7.0, 8.0, 9.0, 2.0], 6: [5.0, 6.0, 4.0, 3.0, 1.0, 7.0, 8.0, 9.0, 2.0], 7: [5.0, 6.0, 4.0, 3.0, 1.0, 7.0, 8.0, 9.0, 2.0], 8: [5.0, 6.0, 4.0, 3.0, 1.0, 7.0, 9.0, 2.0], 9: [5.0, 6.0, 4.0, 3.0, 1.0, 7.0, 8.0, 9.0, 2.0], 10: [5.0, 6.0, 4.0, 3.0, 1.0, 7.0, 8.0, 9.0, 2.0], 11: [4.0, 3.0, 1.0, 9.0, 2.0], 12: [5.0, 6.0, 1.0, 7.0, 8.0, 9.0, 2.0], 13: [5.0, 6.0, 4.0, 3.0, 1.0, 7.0, 8.0, 9.0, 2.0], 14: [1.0, 9.0, 2.0]}\n"
     ]
    }
   ],
   "source": [
    "# '평균기온(°C)'의 각 범주를 고려하여 데이터를 분할\n",
    "train_data = []\n",
    "val_data = []\n",
    "test_data = []\n",
    "# 각 user별로 온도 범주의 데이터가 적은 경우 기록\n",
    "user_category_not_valid = {}\n",
    "\n",
    "for user in df_limit['userId'].unique():\n",
    "    for category in df_limit['평균기온(°C)'].unique():\n",
    "        category_data = df_limit[(df_limit['평균기온(°C)'] == category) & (df_limit['userId'] == user)]\n",
    "        \n",
    "        if category_data.shape[0] < 20:\n",
    "            if user not in user_category_not_valid:\n",
    "                user_category_not_valid[user] = [category]\n",
    "            else:\n",
    "                user_category_not_valid[user].append(category)\n",
    "            train_data.append(category_data)\n",
    "            continue\n",
    "\n",
    "        # 먼저 전체 데이터의 50%를 훈련 데이터로 분할\n",
    "        train, temp = train_test_split(category_data, test_size=0.5, random_state=42)\n",
    "        \n",
    "        # 남은 데이터를 반으로 나누어 검증 데이터와 테스트 데이터로 분할\n",
    "        val, test = train_test_split(temp, test_size=0.3, random_state=42)\n",
    "        \n",
    "        train_data.append(train)\n",
    "        val_data.append(val)\n",
    "        test_data.append(test)\n",
    "\n",
    "print(user_category_not_valid)\n",
    "# 각 데이터 세트를 하나의 DataFrame으로 병합\n",
    "train_data_df = pd.concat(train_data)\n",
    "val_data_df = pd.concat(val_data)\n",
    "test_data_df = pd.concat(test_data)\n",
    "\n",
    "# 평균기온 column을 범주형으로 변경\n",
    "train_data_df['평균기온(°C)'] = train_data_df['평균기온(°C)'].astype('float64')\n",
    "val_data_df['평균기온(°C)'] = val_data_df['평균기온(°C)'].astype('float64')\n",
    "test_data_df['평균기온(°C)'] = test_data_df['평균기온(°C)'].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(570, 167, 103)"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_df['옷 조합'].nunique(), val_data_df['옷 조합'].nunique(), test_data_df['옷 조합'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'가디건, 구두/로퍼, 긴팔 티, 면바지, 액세서리 없음, 재킷',\n",
       " '가디건, 구두/로퍼, 데님팬츠, 반팔 티, 액세서리 없음',\n",
       " '가디건, 기타 모자, 긴팔 티, 데님팬츠, 스니커즈/캔버스',\n",
       " '가디건, 데님팬츠, 반팔 티, 셔츠/블라우스, 스니커즈/캔버스, 액세서리 없음',\n",
       " '가디건, 데님팬츠, 반팔 티, 스니커즈/캔버스, 액세서리 없음',\n",
       " '가디건, 면바지, 반팔 티, 셔츠/블라우스, 스니커즈/캔버스, 액세서리 없음',\n",
       " '구두/로퍼, 기타 모자, 긴팔 티, 데님팬츠, 재킷',\n",
       " '구두/로퍼, 기타 모자, 긴팔 티, 데님팬츠, 집업',\n",
       " '구두/로퍼, 기타 모자, 데님팬츠, 반팔 티, 셔츠/블라우스, 아우터 없음',\n",
       " '구두/로퍼, 기타 모자, 데님팬츠, 반팔 티, 아우터 없음',\n",
       " '구두/로퍼, 기타 모자, 맨투맨, 반바지, 아우터 없음, 장목양말',\n",
       " '구두/로퍼, 니트, 데님팬츠, 반팔 티, 아우터 없음, 액세서리 없음',\n",
       " '구두/로퍼, 니트, 데님팬츠, 반팔 티, 액세서리 없음, 코트',\n",
       " '구두/로퍼, 니트, 면바지, 반팔 티, 액세서리 없음, 코트',\n",
       " '구두/로퍼, 데님팬츠, 반팔 티, 셔츠/블라우스, 아우터 없음, 액세서리 없음',\n",
       " '구두/로퍼, 데님팬츠, 반팔 티, 셔츠/블라우스, 액세서리 없음, 재킷',\n",
       " '구두/로퍼, 데님팬츠, 반팔 티, 아우터 없음, 액세서리 없음',\n",
       " '구두/로퍼, 데님팬츠, 반팔 티, 액세서리 없음, 재킷',\n",
       " '구두/로퍼, 맨투맨, 면바지, 반팔 티, 아우터 없음, 액세서리 없음',\n",
       " '구두/로퍼, 면바지, 반팔 티, 셔츠/블라우스, 아우터 없음, 액세서리 없음',\n",
       " '구두/로퍼, 면바지, 반팔 티, 셔츠/블라우스, 액세서리 없음, 재킷',\n",
       " '구두/로퍼, 면바지, 반팔 티, 셔츠/블라우스, 액세서리 없음, 집업',\n",
       " '구두/로퍼, 면바지, 반팔 티, 아우터 없음, 액세서리 없음',\n",
       " '구두/로퍼, 반바지, 반팔 셔츠/블라우스, 반팔 티, 아우터 없음, 장목양말',\n",
       " '구두/로퍼, 반바지, 반팔 티, 셔츠/블라우스, 아우터 없음, 장목양말',\n",
       " '구두/로퍼, 반바지, 반팔 티, 장목양말, 재킷',\n",
       " '기타 모자, 긴팔 티, 데님팬츠, 레더부츠, 재킷',\n",
       " '기타 모자, 긴팔 티, 데님팬츠, 레더부츠, 코트',\n",
       " '기타 모자, 긴팔 티, 데님팬츠, 스니커즈/캔버스, 아우터 없음',\n",
       " '기타 모자, 긴팔 티, 데님팬츠, 아우터 없음, 운동화',\n",
       " '기타 모자, 긴팔 티, 데님팬츠, 운동화, 재킷',\n",
       " '기타 모자, 나일론 팬츠, 바람막이, 반팔 티, 스니커즈/캔버스',\n",
       " '기타 모자, 나일론 팬츠, 반팔 티, 스니커즈/캔버스, 아우터 없음',\n",
       " '기타 모자, 나일론 팬츠, 반팔 티, 아우터 없음, 운동화',\n",
       " '기타 모자, 니트, 반바지, 반팔 티, 스니커즈/캔버스, 아우터 없음, 장목양말',\n",
       " '기타 모자, 데님팬츠, 맨투맨, 반팔 티, 스니커즈/캔버스, 아우터 없음',\n",
       " '기타 모자, 데님팬츠, 맨투맨, 반팔 티, 아우터 없음, 운동화',\n",
       " '기타 모자, 데님팬츠, 바람막이, 반팔 티, 운동화',\n",
       " '기타 모자, 데님팬츠, 반팔 티, 셔츠/블라우스, 아우터 없음, 운동화',\n",
       " '기타 모자, 데님팬츠, 반팔 티, 스니커즈/캔버스, 아우터 없음',\n",
       " '기타 모자, 데님팬츠, 반팔 티, 스니커즈/캔버스, 아우터 없음, 후드티',\n",
       " '기타 모자, 데님팬츠, 반팔 티, 스니커즈/캔버스, 재킷',\n",
       " '기타 모자, 데님팬츠, 반팔 티, 스니커즈/캔버스, 패딩조끼, 후드티',\n",
       " '기타 모자, 데님팬츠, 반팔 티, 아우터 없음, 운동화',\n",
       " '기타 모자, 데님팬츠, 반팔 티, 아우터 없음, 운동화, 후드티',\n",
       " '기타 모자, 데님팬츠, 반팔 티, 운동화, 재킷',\n",
       " '기타 모자, 면바지, 반팔 티, 스니커즈/캔버스, 아우터 없음',\n",
       " '기타 모자, 반바지, 반팔 티, 샌들/슬리퍼, 아우터 없음',\n",
       " '기타 모자, 반바지, 반팔 티, 스니커즈/캔버스, 아우터 없음, 장목양말',\n",
       " '기타 모자, 반바지, 반팔 티, 아우터 없음, 운동화, 장목양말',\n",
       " '기타 모자, 반팔 티, 스니커즈/캔버스, 아우터 없음, 카고바지',\n",
       " '기타 모자, 반팔 티, 아우터 없음, 운동화, 카고바지, 후드티',\n",
       " '긴팔 티, 데님팬츠, 스니커즈/캔버스, 아우터 없음, 액세서리 없음',\n",
       " '긴팔 티, 데님팬츠, 스니커즈/캔버스, 액세서리 없음, 재킷',\n",
       " '긴팔 티, 면바지, 스니커즈/캔버스, 아우터 없음, 액세서리 없음',\n",
       " '니트, 데님팬츠, 반팔 티, 스니커즈/캔버스, 아우터 없음, 액세서리 없음',\n",
       " '니트, 데님팬츠, 반팔 티, 스니커즈/캔버스, 액세서리 없음, 패딩조끼',\n",
       " '니트, 면바지, 반팔 티, 스니커즈/캔버스, 아우터 없음, 액세서리 없음',\n",
       " '니트, 면바지, 반팔 티, 스니커즈/캔버스, 액세서리 없음, 코트',\n",
       " '데님팬츠, 맨투맨, 반팔 티, 스니커즈/캔버스, 아우터 없음, 액세서리 없음',\n",
       " '데님팬츠, 맨투맨, 반팔 티, 스니커즈/캔버스, 액세서리 없음, 코트',\n",
       " '데님팬츠, 반팔 티, 비니, 스니커즈/캔버스, 아우터 없음',\n",
       " '데님팬츠, 반팔 티, 샌들/슬리퍼, 아우터 없음, 액세서리 없음',\n",
       " '데님팬츠, 반팔 티, 샌들/슬리퍼, 액세서리 없음, 재킷',\n",
       " '데님팬츠, 반팔 티, 셔츠/블라우스, 스니커즈/캔버스, 아우터 없음, 액세서리 없음',\n",
       " '데님팬츠, 반팔 티, 셔츠/블라우스, 아우터 없음, 액세서리 없음, 운동화',\n",
       " '데님팬츠, 반팔 티, 스니커즈/캔버스, 아우터 없음, 액세서리 없음',\n",
       " '데님팬츠, 반팔 티, 스니커즈/캔버스, 아우터 없음, 액세서리 없음, 후드티',\n",
       " '데님팬츠, 반팔 티, 스니커즈/캔버스, 액세서리 없음, 재킷',\n",
       " '데님팬츠, 반팔 티, 스니커즈/캔버스, 액세서리 없음, 코트, 후드티',\n",
       " '데님팬츠, 반팔 티, 스니커즈/캔버스, 액세서리 없음, 패딩조끼, 후드티',\n",
       " '데님팬츠, 반팔 티, 아우터 없음, 액세서리 없음, 운동화',\n",
       " '데님팬츠, 반팔 티, 액세서리 없음, 운동화, 재킷',\n",
       " '데님팬츠, 액세서리 없음, 운동화, 재킷, 후드티',\n",
       " '맨투맨, 면바지, 반팔 티, 스니커즈/캔버스, 아우터 없음, 액세서리 없음',\n",
       " '맨투맨, 반팔 티, 아우터 없음, 액세서리 없음, 운동화, 트레이닝/조거 팬츠',\n",
       " '면바지, 반팔 티, 샌들/슬리퍼, 아우터 없음, 액세서리 없음',\n",
       " '면바지, 반팔 티, 스니커즈/캔버스, 아우터 없음, 액세서리 없음',\n",
       " '면바지, 반팔 티, 스니커즈/캔버스, 액세서리 없음, 재킷',\n",
       " '반바지, 반팔 티, 스니커즈/캔버스, 아우터 없음, 장목양말',\n",
       " '반팔 티, 스니커즈/캔버스, 아우터 없음, 액세서리 없음, 카고바지',\n",
       " '반팔 티, 아우터 없음, 액세서리 없음, 운동화, 트레이닝/조거 팬츠'}"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_data_df와 val_data_df의 옷 조합 column의 고유한 값이 같은 경우의 개수\n",
    "val_data_df['옷 조합'].unique()\n",
    "train_data_df['옷 조합'].unique()\n",
    "set(train_data_df['옷 조합'].unique()) & set(val_data_df['옷 조합'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# 중복된 행 찾기\\nduplicated_rows = train_data_df[train_data_df.duplicated(['옷 조합'], keep=False)]\\nduplicated_rows.sort_values(by='옷 조합')\""
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# 중복된 행 찾기\n",
    "duplicated_rows = train_data_df[train_data_df.duplicated(['옷 조합'], keep=False)]\n",
    "duplicated_rows.sort_values(by='옷 조합')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>옷 조합</th>\n",
       "      <th>평균기온(°C)</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>14</td>\n",
       "      <td>구두/로퍼, 기타 모자, 긴팔 티, 데님팬츠, 코트</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816</th>\n",
       "      <td>14</td>\n",
       "      <td>기타 모자, 긴팔 티, 데님팬츠, 스니커즈/캔버스, 재킷</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>14</td>\n",
       "      <td>기타 모자, 나일론 팬츠, 반팔 티, 스니커즈/캔버스, 아우터 없음</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>844</th>\n",
       "      <td>14</td>\n",
       "      <td>기타 모자, 데님팬츠, 바람막이, 반팔 티, 운동화</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850</th>\n",
       "      <td>14</td>\n",
       "      <td>기타 모자, 데님팬츠, 반팔 티, 스니커즈/캔버스, 아우터 없음, 후드티</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>14</td>\n",
       "      <td>기타 모자, 면바지, 반팔 티, 스니커즈/캔버스, 아우터 없음</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>14</td>\n",
       "      <td>기타 모자, 반바지, 반팔 티, 스니커즈/캔버스, 아우터 없음, 장목양말</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>14</td>\n",
       "      <td>기타 모자, 반바지, 반팔 티, 스니커즈/캔버스, 아우터 없음, 장목양말</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>14</td>\n",
       "      <td>기타 모자, 반팔 티, 스니커즈/캔버스, 아우터 없음, 카고바지</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>14</td>\n",
       "      <td>기타 모자, 반팔 티, 아우터 없음, 운동화, 카고바지</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     userId                                      옷 조합  평균기온(°C)  count\n",
       "790      14              구두/로퍼, 기타 모자, 긴팔 티, 데님팬츠, 코트       2.0      2\n",
       "816      14           기타 모자, 긴팔 티, 데님팬츠, 스니커즈/캔버스, 재킷       3.0      2\n",
       "834      14     기타 모자, 나일론 팬츠, 반팔 티, 스니커즈/캔버스, 아우터 없음       9.0      2\n",
       "844      14              기타 모자, 데님팬츠, 바람막이, 반팔 티, 운동화       4.0      2\n",
       "850      14  기타 모자, 데님팬츠, 반팔 티, 스니커즈/캔버스, 아우터 없음, 후드티       3.0      2\n",
       "863      14        기타 모자, 면바지, 반팔 티, 스니커즈/캔버스, 아우터 없음       7.0      2\n",
       "875      14  기타 모자, 반바지, 반팔 티, 스니커즈/캔버스, 아우터 없음, 장목양말       7.0      2\n",
       "876      14  기타 모자, 반바지, 반팔 티, 스니커즈/캔버스, 아우터 없음, 장목양말       8.0      2\n",
       "884      14       기타 모자, 반팔 티, 스니커즈/캔버스, 아우터 없음, 카고바지       9.0      2\n",
       "887      14            기타 모자, 반팔 티, 아우터 없음, 운동화, 카고바지       5.0      2"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# user-item-temperature의 3-dimensional tensor를 생성\n",
    "\n",
    "# 사용자, 아이템, 온도 범주별로 그룹화하고 각 그룹의 크기를 계산\n",
    "grouped = train_data_df.groupby(['userId', '옷 조합', '평균기온(°C)'], observed=True).size().reset_index(name='count')\n",
    "grouped[(grouped['userId'] == 14) & (grouped['count'] > 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# 3차원 텐서 생성\\ntensor = np.zeros((train_data_df['userId'].nunique(), train_data_df['옷 조합'].nunique(), train_data_df['평균기온(°C)'].nunique()))\\n\\nfor _, row in grouped.iterrows():\\n    user_idx = train_data_df['userId'].unique().tolist().index(row['userId'])\\n    item_idx = train_data_df['옷 조합'].unique().tolist().index(row['옷 조합'])\\n    temp_idx = train_data_df['평균기온(°C)'].unique().tolist().index(row['평균기온(°C)'])\\n    tensor[user_idx, item_idx, temp_idx] = row['count']\""
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# 3차원 텐서 생성\n",
    "tensor = np.zeros((train_data_df['userId'].nunique(), train_data_df['옷 조합'].nunique(), train_data_df['평균기온(°C)'].nunique()))\n",
    "\n",
    "for _, row in grouped.iterrows():\n",
    "    user_idx = train_data_df['userId'].unique().tolist().index(row['userId'])\n",
    "    item_idx = train_data_df['옷 조합'].unique().tolist().index(row['옷 조합'])\n",
    "    temp_idx = train_data_df['평균기온(°C)'].unique().tolist().index(row['평균기온(°C)'])\n",
    "    tensor[user_idx, item_idx, temp_idx] = row['count']'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# 고유한 값들의 리스트를 미리 생성\\nuser_unique_list = sorted(train_data_df['userId'].unique().tolist())\\nitem_unique_list = sorted(train_data_df['옷 조합'].unique().tolist())\\ntemp_unique_list = sorted(train_data_df['평균기온(°C)'].unique().tolist())\\n\\n# 3차원 텐서 생성\\ntensor = np.zeros((len(user_unique_list), len(item_unique_list), len(temp_unique_list)))\\n\\nfor _, row in grouped.iterrows():\\n    user_idx = user_unique_list.index(row['userId'])\\n    item_idx = item_unique_list.index(row['옷 조합'])\\n    temp_idx = temp_unique_list.index(row['평균기온(°C)'])\\n    tensor[user_idx, item_idx, temp_idx] = row['count']\""
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# 고유한 값들의 리스트를 미리 생성\n",
    "user_unique_list = sorted(train_data_df['userId'].unique().tolist())\n",
    "item_unique_list = sorted(train_data_df['옷 조합'].unique().tolist())\n",
    "temp_unique_list = sorted(train_data_df['평균기온(°C)'].unique().tolist())\n",
    "\n",
    "# 3차원 텐서 생성\n",
    "tensor = np.zeros((len(user_unique_list), len(item_unique_list), len(temp_unique_list)))\n",
    "\n",
    "for _, row in grouped.iterrows():\n",
    "    user_idx = user_unique_list.index(row['userId'])\n",
    "    item_idx = item_unique_list.index(row['옷 조합'])\n",
    "    temp_idx = temp_unique_list.index(row['평균기온(°C)'])\n",
    "    tensor[user_idx, item_idx, temp_idx] = row['count']'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot_table을 이용한 user-item matrix 생성\n",
    "train_data_df_value = train_data_df.copy()\n",
    "train_data_df_value['평균기온(°C)'] = train_data_df_value['평균기온(°C)'].astype('float32')\n",
    "UI_temp = train_data_df_value.pivot_table(index='userId', columns='옷 조합', values='평균기온(°C)', fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UI_val = UI_temp.copy()\n",
    "# UI_val의 값을 모두 0으로 초기화\n",
    "UI_val = UI_val.map(lambda x: 0.0)\n",
    "for user in UI_temp.index:\n",
    "    for item in UI_temp.columns:\n",
    "        # validation에 해당 user-item이 있는 경우 해당 user-item의 평균을 기록\n",
    "        if item in val_data_df[val_data_df['userId'] == user]['옷 조합'].values:\n",
    "            UI_val.loc[user, item] = val_data_df[(val_data_df['userId'] == user) & (val_data_df['옷 조합'] == item)]['평균기온(°C)'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UI_test = UI_temp.copy()\n",
    "# UI_val의 값을 모두 0으로 초기화\n",
    "UI_test = UI_test.map(lambda x: 0.0)\n",
    "for user in UI_temp.index:\n",
    "    for item in UI_temp.columns:\n",
    "        # validation에 해당 user-item이 있는 경우 해당 user-item의 평균을 기록\n",
    "        if item in test_data_df[test_data_df['userId'] == user]['옷 조합'].values:\n",
    "            UI_test.loc[user, item] = test_data_df[(test_data_df['userId'] == user) & (test_data_df['옷 조합'] == item)]['평균기온(°C)'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112, 64)"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# UI_val, UI_test의 값이 0이 아닌 경우의 개수\n",
    "UI_val[UI_val != 0].count().sum(), UI_test[UI_test != 0].count().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot_table을 이용한 user_\n",
    "UI_count = train_data_df.pivot_table( index='userId', columns='옷 조합', aggfunc='size', fill_value=0)\n",
    "# 해당 user의 총 예제 개수로 각각의 row를 나눔\n",
    "UI_count_div = UI_count.div(UI_count.sum(axis=1), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 2, 1, 1, 1, 1, 1, 2, 3, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1,\n",
       "       1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 9, 1, 1, 1, 3, 1, 2, 1, 1, 1, 1,\n",
       "       3, 1, 1, 2, 1, 1, 1, 2, 3, 4, 2, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       2, 1, 1, 1, 2, 2, 1, 1, 1, 3, 3, 5, 1, 5, 1, 2, 1, 1, 2, 3, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 2, 1, 1, 1, 1, 5, 3, 1, 2, 2, 1,\n",
       "       1, 1, 2, 4, 2, 1, 1, 2, 1, 3, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2,\n",
       "       1, 1, 1, 1, 3, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 2, 2, 1, 1, 2, 1, 1, 1, 2, 2, 1, 6, 3, 3, 2, 1, 1, 2, 1, 5,\n",
       "       1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 3, 3, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 3,\n",
       "       1, 2, 1, 2, 1, 1, 1, 1, 2, 2, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 5, 1,\n",
       "       1, 1, 2, 1, 1, 1, 1, 4, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 3, 3, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 2, 3, 3, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 5, 1, 4, 3, 1, 4, 1, 5, 1, 2, 1, 1, 1, 1, 1, 4, 2,\n",
       "       4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 3, 2, 1, 1, 1, 1,\n",
       "       4, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 3, 1, 1, 1, 3, 1,\n",
       "       1, 1, 4, 5, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 3,\n",
       "       2, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# user-item matrix에 기록된 값이 존재하는 경우 1, 아닌 경우 0으로 변환하여 R_df에 기록\n",
    "R_df = UI_temp.map(lambda x: 1 if x != 0 else 0)\n",
    "R_np = np.array(R_df)\n",
    "R_np.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# tensor에 기록된 값이 존재하는 경우 1, 존재하지 않는 경우 0\\nR_np = np.where(tensor > 0, 1, 0)\\nsum_along_all_other_axes = R_np.sum(axis=tuple(range(1, R_np.ndim)))\\nsum_along_all_other_axes'"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# tensor에 기록된 값이 존재하는 경우 1, 존재하지 않는 경우 0\n",
    "R_np = np.where(tensor > 0, 1, 0)\n",
    "sum_along_all_other_axes = R_np.sum(axis=tuple(range(1, R_np.ndim)))\n",
    "sum_along_all_other_axes'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 열의 합이 2 이상(여러 유저가 해당 옷 조합을 선택한 경우)인 열을 찾음\n",
    "columns_with_sum_over_2 = R_df.columns[R_df.sum() >= 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'UI_temp[columns_with_sum_over_2]'"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''UI_temp[columns_with_sum_over_2]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'columns_with_sum_over_2'"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''columns_with_sum_over_2'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# 해당 조합의 인덱스\\ncolumn_index = []\\nfor i in columns_with_sum_over_2:\\n    column_index.append(R_df.columns.get_loc(i))\\n    column_index'"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# 해당 조합의 인덱스\n",
    "column_index = []\n",
    "for i in columns_with_sum_over_2:\n",
    "    column_index.append(R_df.columns.get_loc(i))\n",
    "    column_index'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for row in R_np:\\n    print(row)'"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''for row in R_np:\n",
    "    print(row)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(570, 14)\n"
     ]
    }
   ],
   "source": [
    "# CF를 위한 초기값 설정\n",
    "Y = np.array(UI_temp) \n",
    "Y = Y.T\n",
    "count = np.array(UI_count_div)\n",
    "count = count.T\n",
    "print(Y.shape)\n",
    "R = Y != 0 \n",
    "n_u = Y.shape[1]\n",
    "n_o = Y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation, test\n",
    "Y_val = np.array(UI_val)\n",
    "Y_val = Y_val.T\n",
    "Y_test = np.array(UI_test)\n",
    "Y_test = Y_test.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기록이 존재하는 값의 평균을 구함\n",
    "o_sum = Y.sum(axis=1)\n",
    "o_count = R.sum(axis=1)\n",
    "o_mean = o_sum / o_count\n",
    "o_mean = o_mean.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Y[column_index]'"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Y[column_index]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_stand = Y - (o_mean * R)\n",
    "Y_val_stand = Y_val - (o_mean * (Y_val != 0))\n",
    "Y_test_stand = Y_test - (o_mean * (Y_test != 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cofi_cost_func_v(O, U, b, Y, R, lambda_):\n",
    "    j = (tf.linalg.matmul(O, tf.transpose(U)) + b - Y )*R\n",
    "    J = 0.5 * tf.reduce_sum(j**2) + (lambda_/2) * (tf.reduce_sum(O**2) + tf.reduce_sum(U**2))\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user, outfit의 수\n",
    "n_o, n_u = Y.shape\n",
    "# latent factor의 수\n",
    "num_features = 30\n",
    "\n",
    "# (U,O)를 초기화하고 tf.Variable로 등록하여 추적\n",
    "tf.random.set_seed(1234) # for consistent results\n",
    "U = tf.Variable(tf.random.normal((n_u,  num_features),dtype=tf.float64),  name='U')\n",
    "O = tf.Variable(tf.random.normal((n_o, num_features),dtype=tf.float64),  name='O')\n",
    "b = tf.Variable(tf.random.normal((1,          n_u),   dtype=tf.float64),  name='b')\n",
    "\n",
    "# optimizer 초기화\n",
    "optimizer = keras.optimizers.Adam(learning_rate=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "J = cofi_cost_func_v(O, U, b, Y_stand, R, 1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost (with regularization): 27376.00\n"
     ]
    }
   ],
   "source": [
    "print(f\"Cost (with regularization): {J:0.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at iteration 20: 1901.2\n",
      "validation loss at iteration 20: 1932.5\n",
      "Training loss at iteration 40: 381.5\n",
      "validation loss at iteration 40: 539.1\n",
      "Training loss at iteration 60: 121.3\n",
      "validation loss at iteration 60: 299.3\n",
      "Training loss at iteration 80: 71.7\n",
      "validation loss at iteration 80: 257.0\n",
      "Training loss at iteration 100: 60.6\n",
      "validation loss at iteration 100: 246.2\n",
      "Training loss at iteration 120: 57.2\n",
      "validation loss at iteration 120: 242.4\n",
      "Training loss at iteration 140: 55.8\n",
      "validation loss at iteration 140: 240.4\n",
      "Training loss at iteration 160: 55.1\n",
      "validation loss at iteration 160: 239.2\n",
      "Training loss at iteration 180: 54.7\n",
      "validation loss at iteration 180: 238.4\n",
      "Training loss at iteration 200: 54.4\n",
      "validation loss at iteration 200: 237.9\n"
     ]
    }
   ],
   "source": [
    "iterations = 200\n",
    "lambda_ = 1\n",
    "for iter in range(iterations):\n",
    "    # TensorFlow의 GradientTape 사용\n",
    "    # 연산을 기록하여 cost에 대한 gradient를 자동으로 계산\n",
    "    with tf.GradientTape() as tape:\n",
    "\n",
    "        # cost 계산 (forward pass included in cost)\n",
    "        cost_value = cofi_cost_func_v(O, U, b, Y_stand, R, lambda_)\n",
    "\n",
    "    # GradientTape를 통해 자동 미분\n",
    "    # loss에 대한 trainable parameter의 gradient를 계산\n",
    "    grads = tape.gradient( cost_value, [O,U,b] )\n",
    "\n",
    "    # optimizer를 사용하여 trainable parameter를 업데이트\n",
    "    optimizer.apply_gradients( zip(grads, [O,U,b]) )\n",
    "\n",
    "    # Log periodically.\n",
    "    if (iter + 1) % 20 == 0:\n",
    "        print(f\"Training loss at iteration {iter + 1}: {cost_value:0.1f}\")\n",
    "        print(f'validation loss at iteration {iter + 1}: {cofi_cost_func_v(O, U, b, Y_val_stand, R, lambda_):0.1f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련된 tf.Variable 파일로 저장\n",
    "model_version = '1.0'\n",
    "checkpoint_path = f'../model/{model_version}/'\n",
    "os.makedirs(checkpoint_path, exist_ok=True)\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer, O=O, U=U, b=b)\n",
    "checkpoint.save(os.path.join(checkpoint_path, 'parameters.ckpt'))\n",
    "UI_temp.to_csv(os.path.join(checkpoint_path, 'UI_temp.csv'))\n",
    "\n",
    "# UI_temp및 UI_count_div를 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.0"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'real_temperature'는 실제 온도입니다.\n",
    "real_temperature = 14.8\n",
    "\n",
    "# 실제 온도를 범주화합니다.\n",
    "categorized_temperature = pd.cut([real_temperature], bins=np.round(np.arange(min_temp -5, max_temp+5, 5), 1), labels=np.arange(0, (max_temp-min_temp)//5+2))\n",
    "\n",
    "\n",
    "# 첫 번째 요소를 선택하여 범주화된 온도를 얻습니다.\n",
    "categorized_temperature = categorized_temperature[0]\n",
    "categorized_temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# 예측을 수행하기 위해 모든 user-item에 대한 예측값을 계산\\np = np.matmul(O.numpy(), np.transpose(U.numpy())) + b.numpy()\\n# 실제 온도\\n# 평균을 적용하고 temp를 빼서 값이 작을수록 실제 온도에 가깝도록 함. 이 때 각 user-item의 사용 횟수를 가중하여 많이 사용한 item이 추천되도록 함\\npm = np.power(p + o_mean - categorized_temperature, 2)  -count * 0.4\\n\\n# 각 user마다 반복\\nfor i in range(n_u) :\\n    my_predictions = pm[:,i]\\n\\n    # sort predictions\\n    ix = tf.argsort(my_predictions, direction='ASCENDING')\\n\\n    df_predict = UI_temp[UI_temp.columns[ix[0:10]]].copy()\\n    df_predict = df_predict.round(0)\\n    df_predict.to_csv(f'../data/predictions/male/user_{i+1}_predictions.csv')\""
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# 예측을 수행하기 위해 모든 user-item에 대한 예측값을 계산\n",
    "p = np.matmul(O.numpy(), np.transpose(U.numpy())) + b.numpy()\n",
    "# 실제 온도\n",
    "# 평균을 적용하고 temp를 빼서 값이 작을수록 실제 온도에 가깝도록 함. 이 때 각 user-item의 사용 횟수를 가중하여 많이 사용한 item이 추천되도록 함\n",
    "pm = np.power(p + o_mean - categorized_temperature, 2)  -count * 0.4\n",
    "\n",
    "# 각 user마다 반복\n",
    "for i in range(n_u) :\n",
    "    my_predictions = pm[:,i]\n",
    "\n",
    "    # sort predictions\n",
    "    ix = tf.argsort(my_predictions, direction='ASCENDING')\n",
    "\n",
    "    df_predict = UI_temp[UI_temp.columns[ix[0:10]]].copy()\n",
    "    df_predict = df_predict.round(0)\n",
    "    df_predict.to_csv(f'../data/predictions/male/user_{i+1}_predictions.csv')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: [3.0, 1.0, 7.0, 8.0, 9.0, 2.0],\n",
       " 2: [5.0, 4.0, 3.0, 1.0, 7.0, 9.0, 2.0],\n",
       " 3: [5.0, 1.0, 9.0, 2.0],\n",
       " 4: [5.0, 6.0, 4.0, 3.0, 1.0, 7.0, 8.0, 9.0, 2.0],\n",
       " 5: [5.0, 6.0, 4.0, 3.0, 1.0, 7.0, 8.0, 9.0, 2.0],\n",
       " 6: [5.0, 6.0, 4.0, 3.0, 1.0, 7.0, 8.0, 9.0, 2.0],\n",
       " 7: [5.0, 6.0, 4.0, 3.0, 1.0, 7.0, 8.0, 9.0, 2.0],\n",
       " 8: [5.0, 6.0, 4.0, 3.0, 1.0, 7.0, 9.0, 2.0],\n",
       " 9: [5.0, 6.0, 4.0, 3.0, 1.0, 7.0, 8.0, 9.0, 2.0],\n",
       " 10: [5.0, 6.0, 4.0, 3.0, 1.0, 7.0, 8.0, 9.0, 2.0],\n",
       " 11: [4.0, 3.0, 1.0, 9.0, 2.0],\n",
       " 12: [5.0, 6.0, 1.0, 7.0, 8.0, 9.0, 2.0],\n",
       " 13: [5.0, 6.0, 4.0, 3.0, 1.0, 7.0, 8.0, 9.0, 2.0],\n",
       " 14: [1.0, 9.0, 2.0]}"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_category_not_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1번 user, 5.0도 prediction: Index(['니트, 데님팬츠, 반팔 티, 스니커즈/캔버스, 액세서리 없음, 재킷',\n",
      "       '가디건, 구두/로퍼, 데님팬츠, 반팔 티, 셔츠/블라우스, 액세서리 없음',\n",
      "       '면바지, 반팔 티, 비니, 스니커즈/캔버스, 재킷'],\n",
      "      dtype='object', name='옷 조합')\n",
      "1번 user, 5.0도 label: 81     데님팬츠, 반팔 티, 셔츠/블라우스, 스니커즈/캔버스, 액세서리 없음, 조끼\n",
      "68                 면바지, 아우터 없음, 액세서리 없음, 운동화, 후드티\n",
      "71      데님팬츠, 반팔 티, 셔츠/블라우스, 아우터 없음, 액세서리 없음, 운동화\n",
      "104     면바지, 반팔 티, 셔츠/블라우스, 스니커즈/캔버스, 액세서리 없음, 코트\n",
      "Name: 옷 조합, dtype: object\n",
      "0.0 0.0 0\n",
      "1번 user, 6.0도 prediction: Index(['긴팔 티, 데님팬츠, 스니커즈/캔버스, 액세서리 없음, 재킷', '구두/로퍼, 데님팬츠, 반팔 티, 액세서리 없음, 재킷',\n",
      "       '가디건, 긴팔 티, 면바지, 운동화, 장목양말'],\n",
      "      dtype='object', name='옷 조합')\n",
      "1번 user, 6.0도 label: 41                      구두/로퍼, 기타 모자, 니트, 면바지, 반팔 티, 재킷\n",
      "1                             기타 모자, 반바지, 반팔 티, 운동화, 재킷\n",
      "86    기타 모자, 데님팬츠, 민소매 티, 민소매 티, 반팔 티, 셔츠/블라우스, 스니커즈...\n",
      "76                         긴팔 티, 데님팬츠, 액세서리 없음, 운동화, 재킷\n",
      "Name: 옷 조합, dtype: object\n",
      "0.0 0.0 0\n",
      "1번 user, 4.0도 prediction: Index(['기타 모자, 긴팔 티, 나일론 팬츠, 운동화, 재킷, 집업',\n",
      "       '데님팬츠, 반팔 티, 스니커즈/캔버스, 액세서리 없음, 재킷, 코트',\n",
      "       '구두/로퍼, 데님팬츠, 셔츠/블라우스, 양말, 재킷, 후드티'],\n",
      "      dtype='object', name='옷 조합')\n",
      "1번 user, 4.0도 label: 13    기타 모자, 운동화, 재킷, 트레이닝/조거 팬츠, 후드티\n",
      "6        구두/로퍼, 기타 모자, 긴팔 티, 데님팬츠, 재킷\n",
      "39      구두/로퍼, 긴팔 티, 면바지, 액세서리 없음, 재킷\n",
      "23       구두/로퍼, 니트, 면바지, 바람막이, 비니, 조끼\n",
      "Name: 옷 조합, dtype: object\n",
      "0.0 0.0 0\n",
      "1번 user, 3.0도 데이터가 부족하여 제외합니다.\n",
      "1번 user, 1.0도 데이터가 부족하여 제외합니다.\n",
      "1번 user, 7.0도 데이터가 부족하여 제외합니다.\n",
      "1번 user, 8.0도 데이터가 부족하여 제외합니다.\n",
      "1번 user, 9.0도 데이터가 부족하여 제외합니다.\n",
      "1번 user, 2.0도 데이터가 부족하여 제외합니다.\n",
      "2번 user, 5.0도 데이터가 부족하여 제외합니다.\n",
      "2번 user, 6.0도 prediction: Index(['데님팬츠, 레더부츠, 반팔 티, 액세서리 없음, 재킷', '기타 모자, 데님팬츠, 반팔 티, 스니커즈/캔버스, 점퍼, 집업',\n",
      "       '데님팬츠, 바람막이, 반팔 티, 액세서리 없음, 운동화'],\n",
      "      dtype='object', name='옷 조합')\n",
      "2번 user, 6.0도 label: 174     가디건, 반팔 티, 비니, 스니커즈/캔버스, 카고바지\n",
      "211     기타 모자, 니트, 면바지, 반팔 티, 운동화, 재킷\n",
      "219       나일론 팬츠, 바람막이, 반팔 티, 비니, 운동화\n",
      "170     데님팬츠, 레더부츠, 반팔 티, 액세서리 없음, 재킷\n",
      "115       나일론 팬츠, 바람막이, 반팔 티, 비니, 운동화\n",
      "116    데님팬츠, 바람막이, 반팔 티, 액세서리 없음, 운동화\n",
      "Name: 옷 조합, dtype: object\n",
      "0.6666666666666666 0.4 0.5\n",
      "2번 user, 4.0도 데이터가 부족하여 제외합니다.\n",
      "2번 user, 3.0도 데이터가 부족하여 제외합니다.\n",
      "2번 user, 1.0도 데이터가 부족하여 제외합니다.\n",
      "2번 user, 7.0도 데이터가 부족하여 제외합니다.\n",
      "2번 user, 8.0도 prediction: Index(['반바지, 반팔 티, 스니커즈/캔버스, 아우터 없음, 장목양말',\n",
      "       '반팔 티, 스니커즈/캔버스, 아우터 없음, 액세서리 없음, 트레이닝/조거 팬츠',\n",
      "       '기타 모자, 반바지, 반팔 티, 아우터 없음, 운동화'],\n",
      "      dtype='object', name='옷 조합')\n",
      "2번 user, 8.0도 label: 126                  반바지, 반팔 티, 스니커즈/캔버스, 장목양말, 재킷\n",
      "155              반바지, 반팔 티, 스니커즈/캔버스, 아우터 없음, 장목양말\n",
      "167    반바지, 반팔 셔츠/블라우스, 반팔 티, 샌들/슬리퍼, 아우터 없음, 장목양말\n",
      "151       기타 모자, 반바지, 반팔 티, 스니커즈/캔버스, 아우터 없음, 장목양말\n",
      "136                  구두/로퍼, 반바지, 반팔 티, 액세서리 없음, 재킷\n",
      "Name: 옷 조합, dtype: object\n",
      "0.3333333333333333 0.2 0.25\n",
      "2번 user, 9.0도 데이터가 부족하여 제외합니다.\n",
      "2번 user, 2.0도 데이터가 부족하여 제외합니다.\n",
      "3번 user, 5.0도 데이터가 부족하여 제외합니다.\n",
      "3번 user, 6.0도 prediction: Index(['데님팬츠, 반팔 티, 셔츠/블라우스, 스니커즈/캔버스, 아우터 없음, 액세서리 없음',\n",
      "       '데님팬츠, 맨투맨, 반팔 티, 스니커즈/캔버스, 아우터 없음, 액세서리 없음',\n",
      "       '가디건, 데님팬츠, 반팔 티, 스니커즈/캔버스, 액세서리 없음'],\n",
      "      dtype='object', name='옷 조합')\n",
      "3번 user, 6.0도 label: 240      기타 모자, 긴팔 티, 반바지, 스니커즈/캔버스, 아우터 없음, 장목양말\n",
      "351        구두/로퍼, 니트, 데님팬츠, 반팔 티, 아우터 없음, 액세서리 없음\n",
      "329                 데님팬츠, 레더부츠, 반팔 티, 액세서리 없음, 재킷\n",
      "344     니트, 데님팬츠, 반팔 티, 스니커즈/캔버스, 아우터 없음, 액세서리 없음\n",
      "245     니트, 데님팬츠, 반팔 티, 스니커즈/캔버스, 아우터 없음, 액세서리 없음\n",
      "346    데님팬츠, 반팔 티, 스니커즈/캔버스, 아우터 없음, 액세서리 없음, 후드티\n",
      "243            구두/로퍼, 데님팬츠, 반팔 티, 아우터 없음, 액세서리 없음\n",
      "355                 데님팬츠, 레더부츠, 반팔 티, 액세서리 없음, 재킷\n",
      "Name: 옷 조합, dtype: object\n",
      "0.0 0.0 0\n",
      "3번 user, 4.0도 prediction: Index(['긴팔 티, 데님팬츠, 스니커즈/캔버스, 액세서리 없음, 재킷',\n",
      "       '맨투맨, 반팔 티, 액세서리 없음, 운동화, 코트, 트레이닝/조거 팬츠',\n",
      "       '긴팔 티, 데님팬츠, 셔츠/블라우스, 스니커즈/캔버스, 아우터 없음, 액세서리 없음'],\n",
      "      dtype='object', name='옷 조합')\n",
      "3번 user, 4.0도 label: 267           긴팔 티, 데님팬츠, 바람막이, 스니커즈/캔버스, 액세서리 없음\n",
      "271        데님팬츠, 레더부츠, 반팔 티, 셔츠/블라우스, 액세서리 없음, 재킷\n",
      "281    데님팬츠, 맨투맨, 반팔 티, 스니커즈/캔버스, 아우터 없음, 액세서리 없음\n",
      "321          기타 모자, 니트, 반팔 티, 운동화, 집업, 트레이닝/조거 팬츠\n",
      "Name: 옷 조합, dtype: object\n",
      "0.0 0.0 0\n",
      "3번 user, 3.0도 prediction: Index(['긴팔 티, 데님팬츠, 레더부츠, 머플러, 코트', '구두/로퍼, 니트, 데님팬츠, 반팔 티, 액세서리 없음, 패딩',\n",
      "       '긴팔 티, 니트, 스니커즈/캔버스, 아우터 없음, 액세서리 없음, 트레이닝/조거 팬츠'],\n",
      "      dtype='object', name='옷 조합')\n",
      "3번 user, 3.0도 label: 274         가디건, 긴팔 티, 데님팬츠, 스니커즈/캔버스, 액세서리 없음\n",
      "279          긴팔 티, 데님팬츠, 스니커즈/캔버스, 액세서리 없음, 재킷\n",
      "284          구두/로퍼, 긴팔 티, 니트, 면바지, 액세서리 없음, 코트\n",
      "317    니트, 니트, 데님팬츠, 스니커즈/캔버스, 아우터 없음, 액세서리 없음\n",
      "Name: 옷 조합, dtype: object\n",
      "0.0 0.0 0\n",
      "3번 user, 1.0도 데이터가 부족하여 제외합니다.\n",
      "3번 user, 7.0도 prediction: Index(['데님팬츠, 반팔 티, 스니커즈/캔버스, 아우터 없음, 액세서리 없음',\n",
      "       '면바지, 반팔 티, 샌들/슬리퍼, 아우터 없음, 액세서리 없음',\n",
      "       '데님팬츠, 반팔 티, 셔츠/블라우스, 스니커즈/캔버스, 아우터 없음, 액세서리 없음'],\n",
      "      dtype='object', name='옷 조합')\n",
      "3번 user, 7.0도 label: 363             니트, 반바지, 반팔 티, 스니커즈/캔버스, 아우터 없음, 장목양말\n",
      "367         니트, 데님팬츠, 반팔 티, 스니커즈/캔버스, 아우터 없음, 액세서리 없음\n",
      "467              면바지, 반팔 티, 스니커즈/캔버스, 아우터 없음, 액세서리 없음\n",
      "470                    반바지, 반팔 티, 샌들/슬리퍼, 액세서리 없음, 조끼\n",
      "233                기타 모자, 데님팬츠, 반팔, 셔츠/블라우스, 스니커즈/캔버스\n",
      "455    데님팬츠, 반팔 티, 셔츠/블라우스, 스니커즈/캔버스, 아우터 없음, 액세서리 없음\n",
      "248                구두/로퍼, 데님팬츠, 반팔 티, 아우터 없음, 액세서리 없음\n",
      "479               반바지, 스니커즈/캔버스, 아우터 없음, 액세서리 없음, 후드티\n",
      "247                   기타 모자, 데님팬츠, 반팔 티, 스니커즈/캔버스, 집업\n",
      "Name: 옷 조합, dtype: object\n",
      "0.3333333333333333 0.1111111111111111 0.16666666666666666\n",
      "3번 user, 8.0도 prediction: Index(['데님팬츠, 반팔 티, 스니커즈/캔버스, 아우터 없음, 액세서리 없음',\n",
      "       '면바지, 반팔 티, 스니커즈/캔버스, 아우터 없음, 액세서리 없음',\n",
      "       '반바지, 반팔 티, 샌들/슬리퍼, 아우터 없음, 액세서리 없음'],\n",
      "      dtype='object', name='옷 조합')\n",
      "3번 user, 8.0도 label: 412               기타 모자, 반바지, 반팔 티, 샌들/슬리퍼, 아우터 없음\n",
      "376    맨투맨, 반팔 티, 비니, 스니커즈/캔버스, 아우터 없음, 트레이닝/조거 팬츠\n",
      "423          데님팬츠, 반팔 티, 스니커즈/캔버스, 아우터 없음, 액세서리 없음\n",
      "440             반바지, 반팔 티, 샌들/슬리퍼, 아우터 없음, 액세서리 없음\n",
      "434          데님팬츠, 반팔 티, 스니커즈/캔버스, 아우터 없음, 액세서리 없음\n",
      "383           반바지, 반팔 티, 스니커즈/캔버스, 아우터 없음, 액세서리 없음\n",
      "437          데님팬츠, 반팔 티, 스니커즈/캔버스, 아우터 없음, 액세서리 없음\n",
      "368               구두/로퍼, 반바지, 아우터 없음, 액세서리 없음, 후드티\n",
      "413             구두/로퍼, 데님팬츠, 반팔 티, 아우터 없음, 액세서리 없음\n",
      "Name: 옷 조합, dtype: object\n",
      "0.6666666666666666 0.2857142857142857 0.4\n",
      "3번 user, 9.0도 데이터가 부족하여 제외합니다.\n",
      "3번 user, 2.0도 데이터가 부족하여 제외합니다.\n",
      "4번 user, 5.0도 데이터가 부족하여 제외합니다.\n",
      "4번 user, 6.0도 데이터가 부족하여 제외합니다.\n",
      "4번 user, 4.0도 데이터가 부족하여 제외합니다.\n",
      "4번 user, 3.0도 데이터가 부족하여 제외합니다.\n",
      "4번 user, 1.0도 데이터가 부족하여 제외합니다.\n",
      "4번 user, 7.0도 데이터가 부족하여 제외합니다.\n",
      "4번 user, 8.0도 데이터가 부족하여 제외합니다.\n",
      "4번 user, 9.0도 데이터가 부족하여 제외합니다.\n",
      "4번 user, 2.0도 데이터가 부족하여 제외합니다.\n",
      "5번 user, 5.0도 데이터가 부족하여 제외합니다.\n",
      "5번 user, 6.0도 데이터가 부족하여 제외합니다.\n",
      "5번 user, 4.0도 데이터가 부족하여 제외합니다.\n",
      "5번 user, 3.0도 데이터가 부족하여 제외합니다.\n",
      "5번 user, 1.0도 데이터가 부족하여 제외합니다.\n",
      "5번 user, 7.0도 데이터가 부족하여 제외합니다.\n",
      "5번 user, 8.0도 데이터가 부족하여 제외합니다.\n",
      "5번 user, 9.0도 데이터가 부족하여 제외합니다.\n",
      "5번 user, 2.0도 데이터가 부족하여 제외합니다.\n",
      "6번 user, 5.0도 데이터가 부족하여 제외합니다.\n",
      "6번 user, 6.0도 데이터가 부족하여 제외합니다.\n",
      "6번 user, 4.0도 데이터가 부족하여 제외합니다.\n",
      "6번 user, 3.0도 데이터가 부족하여 제외합니다.\n",
      "6번 user, 1.0도 데이터가 부족하여 제외합니다.\n",
      "6번 user, 7.0도 데이터가 부족하여 제외합니다.\n",
      "6번 user, 8.0도 데이터가 부족하여 제외합니다.\n",
      "6번 user, 9.0도 데이터가 부족하여 제외합니다.\n",
      "6번 user, 2.0도 데이터가 부족하여 제외합니다.\n",
      "7번 user, 5.0도 데이터가 부족하여 제외합니다.\n",
      "7번 user, 6.0도 데이터가 부족하여 제외합니다.\n",
      "7번 user, 4.0도 데이터가 부족하여 제외합니다.\n",
      "7번 user, 3.0도 데이터가 부족하여 제외합니다.\n",
      "7번 user, 1.0도 데이터가 부족하여 제외합니다.\n",
      "7번 user, 7.0도 데이터가 부족하여 제외합니다.\n",
      "7번 user, 8.0도 데이터가 부족하여 제외합니다.\n",
      "7번 user, 9.0도 데이터가 부족하여 제외합니다.\n",
      "7번 user, 2.0도 데이터가 부족하여 제외합니다.\n",
      "8번 user, 5.0도 데이터가 부족하여 제외합니다.\n",
      "8번 user, 6.0도 데이터가 부족하여 제외합니다.\n",
      "8번 user, 4.0도 데이터가 부족하여 제외합니다.\n",
      "8번 user, 3.0도 데이터가 부족하여 제외합니다.\n",
      "8번 user, 1.0도 데이터가 부족하여 제외합니다.\n",
      "8번 user, 7.0도 데이터가 부족하여 제외합니다.\n",
      "8번 user, 8.0도 prediction: Index(['반팔 티, 스니커즈/캔버스, 아우터 없음, 액세서리 없음, 카고바지',\n",
      "       '데님팬츠, 반팔 티, 스니커즈/캔버스, 아우터 없음, 액세서리 없음',\n",
      "       '구두/로퍼, 데님팬츠, 반팔 티, 아우터 없음, 액세서리 없음'],\n",
      "      dtype='object', name='옷 조합')\n",
      "8번 user, 8.0도 label: 663         반팔 티, 아우터 없음, 액세서리 없음, 운동화, 카고바지\n",
      "656    반팔 티, 스니커즈/캔버스, 아우터 없음, 액세서리 없음, 카고바지\n",
      "659           기타 모자, 반팔 티, 아우터 없음, 운동화, 카고바지\n",
      "685          맨투맨, 아우터 없음, 액세서리 없음, 운동화, 카고바지\n",
      "Name: 옷 조합, dtype: object\n",
      "0.3333333333333333 0.25 0.28571428571428575\n",
      "8번 user, 9.0도 데이터가 부족하여 제외합니다.\n",
      "8번 user, 2.0도 데이터가 부족하여 제외합니다.\n",
      "9번 user, 5.0도 데이터가 부족하여 제외합니다.\n",
      "9번 user, 6.0도 데이터가 부족하여 제외합니다.\n",
      "9번 user, 4.0도 데이터가 부족하여 제외합니다.\n",
      "9번 user, 3.0도 데이터가 부족하여 제외합니다.\n",
      "9번 user, 1.0도 데이터가 부족하여 제외합니다.\n",
      "9번 user, 7.0도 데이터가 부족하여 제외합니다.\n",
      "9번 user, 8.0도 데이터가 부족하여 제외합니다.\n",
      "9번 user, 9.0도 데이터가 부족하여 제외합니다.\n",
      "9번 user, 2.0도 데이터가 부족하여 제외합니다.\n",
      "10번 user, 5.0도 데이터가 부족하여 제외합니다.\n",
      "10번 user, 6.0도 데이터가 부족하여 제외합니다.\n",
      "10번 user, 4.0도 데이터가 부족하여 제외합니다.\n",
      "10번 user, 3.0도 데이터가 부족하여 제외합니다.\n",
      "10번 user, 1.0도 데이터가 부족하여 제외합니다.\n",
      "10번 user, 7.0도 데이터가 부족하여 제외합니다.\n",
      "10번 user, 8.0도 데이터가 부족하여 제외합니다.\n",
      "10번 user, 9.0도 데이터가 부족하여 제외합니다.\n",
      "10번 user, 2.0도 데이터가 부족하여 제외합니다.\n",
      "11번 user, 5.0도 prediction: Index(['기타 모자, 데님팬츠, 아우터 없음, 운동화, 후드티', '긴팔 티, 데님팬츠, 액세서리 없음, 운동화, 재킷',\n",
      "       '구두/로퍼, 데님팬츠, 반팔 티, 셔츠/블라우스, 아우터 없음, 액세서리 없음'],\n",
      "      dtype='object', name='옷 조합')\n",
      "11번 user, 5.0도 label: 823    구두/로퍼, 데님팬츠, 반팔 티, 셔츠/블라우스, 아우터 없음, 액세서리 없음\n",
      "806    구두/로퍼, 데님팬츠, 반팔 티, 셔츠/블라우스, 아우터 없음, 액세서리 없음\n",
      "912               기타 모자, 긴팔 티, 운동화, 트레이닝/조거 팬츠, 패딩\n",
      "809        구두/로퍼, 데님팬츠, 반팔 티, 셔츠/블라우스, 액세서리 없음, 재킷\n",
      "Name: 옷 조합, dtype: object\n",
      "0.3333333333333333 0.3333333333333333 0.3333333333333333\n",
      "11번 user, 6.0도 prediction: Index(['구두/로퍼, 데님팬츠, 반팔 티, 셔츠/블라우스, 아우터 없음, 액세서리 없음',\n",
      "       '데님팬츠, 반팔 티, 액세서리 없음, 운동화, 재킷', '기타 모자, 데님팬츠, 반팔 티, 운동화, 재킷'],\n",
      "      dtype='object', name='옷 조합')\n",
      "11번 user, 6.0도 label: 896           기타 모자, 데님팬츠, 맨투맨, 아우터 없음, 운동화\n",
      "813          구두/로퍼, 데님팬츠, 반팔 티, 액세서리 없음, 재킷\n",
      "821           가디건, 구두/로퍼, 기타 모자, 데님팬츠, 반팔 티\n",
      "816            구두/로퍼, 기타 모자, 데님팬츠, 반팔 티, 재킷\n",
      "882    기타 모자, 맨투맨, 반팔 티, 아우터 없음, 운동화, 하의 없음\n",
      "Name: 옷 조합, dtype: object\n",
      "0.0 0.0 0\n",
      "11번 user, 4.0도 데이터가 부족하여 제외합니다.\n",
      "11번 user, 3.0도 데이터가 부족하여 제외합니다.\n",
      "11번 user, 1.0도 데이터가 부족하여 제외합니다.\n",
      "11번 user, 7.0도 prediction: Index(['기타 모자, 데님팬츠, 반팔 티, 아우터 없음, 운동화', '구두/로퍼, 데님팬츠, 반팔 티, 액세서리 없음, 재킷',\n",
      "       '데님팬츠, 반팔 티, 샌들/슬리퍼, 액세서리 없음, 재킷'],\n",
      "      dtype='object', name='옷 조합')\n",
      "11번 user, 7.0도 label: 830                  구두/로퍼, 데님팬츠, 반팔 티, 액세서리 없음, 조끼\n",
      "804               데님팬츠, 반팔 티, 스니커즈/캔버스, 액세서리 없음, 재킷\n",
      "828    데님팬츠, 반팔 티, 샌들/슬리퍼, 셔츠/블라우스, 아우터 없음, 액세서리 없음\n",
      "880                  기타 모자, 데님팬츠, 반팔 티, 아우터 없음, 운동화\n",
      "Name: 옷 조합, dtype: object\n",
      "0.3333333333333333 0.25 0.28571428571428575\n",
      "11번 user, 8.0도 prediction: Index(['데님팬츠, 반팔 티, 아우터 없음, 액세서리 없음, 운동화',\n",
      "       '구두/로퍼, 데님팬츠, 반팔 티, 아우터 없음, 액세서리 없음',\n",
      "       '기타 모자, 반바지, 반팔 티, 셔츠/블라우스, 스니커즈/캔버스, 아우터 없음, 장목양말'],\n",
      "      dtype='object', name='옷 조합')\n",
      "11번 user, 8.0도 label: 848                     구두/로퍼, 기타 모자, 데님팬츠, 반팔 티, 아우터 없음\n",
      "846              데님팬츠, 레인부츠, 반팔 티, 셔츠/블라우스, 아우터 없음, 장목양말\n",
      "875    데님팬츠, 반팔 셔츠/블라우스, 반팔 티, 스니커즈/캔버스, 아우터 없음, 액세서리 없음\n",
      "829                     구두/로퍼, 기타 모자, 긴팔 티, 데님팬츠, 아우터 없음\n",
      "844                            레인부츠, 반바지, 반팔 티, 장목양말, 조끼\n",
      "Name: 옷 조합, dtype: object\n",
      "0.0 0.0 0\n",
      "11번 user, 9.0도 데이터가 부족하여 제외합니다.\n",
      "11번 user, 2.0도 데이터가 부족하여 제외합니다.\n",
      "12번 user, 5.0도 데이터가 부족하여 제외합니다.\n",
      "12번 user, 6.0도 데이터가 부족하여 제외합니다.\n",
      "12번 user, 4.0도 prediction: Index(['구두/로퍼, 면바지, 반팔 티, 셔츠/블라우스, 액세서리 없음, 재킷',\n",
      "       '구두/로퍼, 긴팔 티, 데님팬츠, 액세서리 없음, 재킷',\n",
      "       '니트, 데님팬츠, 반팔 티, 스니커즈/캔버스, 액세서리 없음, 패딩조끼'],\n",
      "      dtype='object', name='옷 조합')\n",
      "12번 user, 4.0도 label: 994                 구두/로퍼, 긴팔 티, 면바지, 액세서리 없음, 재킷\n",
      "977        구두/로퍼, 면바지, 반팔 티, 셔츠/블라우스, 액세서리 없음, 재킷\n",
      "982     맨투맨, 면바지, 반팔 티, 스니커즈/캔버스, 아우터 없음, 액세서리 없음\n",
      "1023       구두/로퍼, 면바지, 반팔 티, 셔츠/블라우스, 액세서리 없음, 코트\n",
      "Name: 옷 조합, dtype: object\n",
      "0.3333333333333333 0.25 0.28571428571428575\n",
      "12번 user, 3.0도 prediction: Index(['니트, 면바지, 반팔 티, 스니커즈/캔버스, 아우터 없음, 액세서리 없음',\n",
      "       '가디건, 구두/로퍼, 긴팔 티, 면바지, 액세서리 없음, 재킷',\n",
      "       '가디건, 구두/로퍼, 긴팔 티, 데님팬츠, 액세서리 없음, 코트'],\n",
      "      dtype='object', name='옷 조합')\n",
      "12번 user, 3.0도 label: 1003    맨투맨, 면바지, 반팔 티, 스니커즈/캔버스, 아우터 없음, 액세서리 없음\n",
      "978            구두/로퍼, 니트, 데님팬츠, 반팔 티, 액세서리 없음, 패딩\n",
      "987                 구두/로퍼, 긴팔 티, 면바지, 액세서리 없음, 재킷\n",
      "1016        니트, 데님팬츠, 반팔 티, 스니커즈/캔버스, 액세서리 없음, 재킷\n",
      "Name: 옷 조합, dtype: object\n",
      "0.0 0.0 0\n",
      "12번 user, 1.0도 데이터가 부족하여 제외합니다.\n",
      "12번 user, 7.0도 데이터가 부족하여 제외합니다.\n",
      "12번 user, 8.0도 데이터가 부족하여 제외합니다.\n",
      "12번 user, 9.0도 데이터가 부족하여 제외합니다.\n",
      "12번 user, 2.0도 데이터가 부족하여 제외합니다.\n",
      "13번 user, 5.0도 데이터가 부족하여 제외합니다.\n",
      "13번 user, 6.0도 데이터가 부족하여 제외합니다.\n",
      "13번 user, 4.0도 데이터가 부족하여 제외합니다.\n",
      "13번 user, 3.0도 데이터가 부족하여 제외합니다.\n",
      "13번 user, 1.0도 데이터가 부족하여 제외합니다.\n",
      "13번 user, 7.0도 데이터가 부족하여 제외합니다.\n",
      "13번 user, 8.0도 데이터가 부족하여 제외합니다.\n",
      "13번 user, 9.0도 데이터가 부족하여 제외합니다.\n",
      "13번 user, 2.0도 데이터가 부족하여 제외합니다.\n",
      "14번 user, 5.0도 prediction: Index(['기타 모자, 반팔 티, 아우터 없음, 운동화, 카고바지',\n",
      "       '구두/로퍼, 기타 모자, 데님팬츠, 반팔 티, 셔츠/블라우스, 아우터 없음',\n",
      "       '기타 모자, 긴팔 티, 운동화, 점퍼, 트레이닝/조거 팬츠'],\n",
      "      dtype='object', name='옷 조합')\n",
      "14번 user, 5.0도 label: 1275       기타 모자, 맨투맨, 반팔 티, 스니커즈/캔버스, 아우터 없음, 카고바지\n",
      "1218    기타 모자, 반바지, 반팔 티, 셔츠/블라우스, 스니커즈/캔버스, 아우터 없음\n",
      "1234                    기타 모자, 긴팔 티, 데님팬츠, 레더부츠, 코트\n",
      "1313               기타 모자, 나일론 팬츠, 반팔 티, 아우터 없음, 운동화\n",
      "Name: 옷 조합, dtype: object\n",
      "0.0 0.0 0\n",
      "14번 user, 6.0도 prediction: Index(['기타 모자, 바람막이, 반바지, 반팔 티, 스니커즈/캔버스, 장목양말',\n",
      "       '구두/로퍼, 기타 모자, 니트, 반바지, 반팔 티, 아우터 없음, 장목양말',\n",
      "       '기타 모자, 반팔 셔츠/블라우스, 반팔 티, 스니커즈/캔버스, 아우터 없음, 카고바지'],\n",
      "      dtype='object', name='옷 조합')\n",
      "14번 user, 6.0도 label: 1306            기타 모자, 데님팬츠, 반팔 티, 스니커즈/캔버스, 재킷\n",
      "1322          기타 모자, 바람막이, 반팔 티, 스니커즈/캔버스, 카고바지\n",
      "1226                기타 모자, 긴팔 티, 데님팬츠, 레더부츠, 코트\n",
      "1222         기타 모자, 니트, 반팔 티, 아우터 없음, 운동화, 카고바지\n",
      "1321    기타 모자, 반바지, 스니커즈/캔버스, 아우터 없음, 장목양말, 후드티\n",
      "1124          기타 모자, 바람막이, 반바지, 반팔 티, 운동화, 장목양말\n",
      "Name: 옷 조합, dtype: object\n",
      "0.0 0.0 0\n",
      "14번 user, 4.0도 prediction: Index(['기타 모자, 긴팔 티, 데님팬츠, 스니커즈/캔버스, 패딩', '기타 모자, 데님팬츠, 바람막이, 반팔 티, 운동화',\n",
      "       '구두/로퍼, 기타 모자, 긴팔 티, 데님팬츠, 코트'],\n",
      "      dtype='object', name='옷 조합')\n",
      "14번 user, 4.0도 label: 1276                 기타 모자, 데님팬츠, 레더부츠, 점퍼, 후드티\n",
      "1284              기타 모자, 데님팬츠, 아우터 없음, 운동화, 후드티\n",
      "1291    기타 모자, 반팔 티, 셔츠/블라우스, 아우터 없음, 운동화, 카고바지\n",
      "1271             기타 모자, 긴팔 티, 나일론 팬츠, 바람막이, 운동화\n",
      "1229        기타 모자, 니트, 데님팬츠, 레더부츠, 반팔 티, 아우터 없음\n",
      "1230            기타 모자, 긴팔 티, 데님팬츠, 스니커즈/캔버스, 패딩\n",
      "Name: 옷 조합, dtype: object\n",
      "0.3333333333333333 0.16666666666666666 0.2222222222222222\n",
      "14번 user, 3.0도 prediction: Index(['기타 모자, 데님팬츠, 반팔 티, 스니커즈/캔버스, 아우터 없음, 후드티',\n",
      "       '구두/로퍼, 기타 모자, 긴팔 티, 데님팬츠, 코트', '기타 모자, 긴팔 티, 데님팬츠, 스니커즈/캔버스, 재킷'],\n",
      "      dtype='object', name='옷 조합')\n",
      "14번 user, 3.0도 label: 1261         기타 모자, 긴팔 티, 데님팬츠, 스니커즈/캔버스, 점퍼\n",
      "1278             구두/로퍼, 기타 모자, 데님팬츠, 점퍼, 후드티\n",
      "1270    구두/로퍼, 기타 모자, 니트, 데님팬츠, 반팔 티, 아우터 없음\n",
      "1249     기타 모자, 데님팬츠, 반팔 티, 아우터 없음, 운동화, 후드티\n",
      "1267    기타 모자, 데님팬츠, 반팔 티, 스니커즈/캔버스, 패딩, 후드티\n",
      "1293          기타 모자, 긴팔 티, 나일론 팬츠, 바람막이, 운동화\n",
      "1248        구두/로퍼, 기타 모자, 긴팔 티, 데님팬츠, 재킷, 코트\n",
      "Name: 옷 조합, dtype: object\n",
      "0.0 0.0 0\n",
      "14번 user, 1.0도 데이터가 부족하여 제외합니다.\n",
      "14번 user, 7.0도 prediction: Index(['반바지, 반팔 티, 스니커즈/캔버스, 아우터 없음, 장목양말', '기타 모자, 데님팬츠, 반팔 티, 아우터 없음, 운동화',\n",
      "       '기타 모자, 반바지, 반팔 티, 스니커즈/캔버스, 아우터 없음, 장목양말'],\n",
      "      dtype='object', name='옷 조합')\n",
      "14번 user, 7.0도 label: 1210     기타 모자, 데님팬츠, 반팔 티, 셔츠/블라우스, 아우터 없음, 운동화\n",
      "1151            기타 모자, 나일론 팬츠, 반팔 티, 아우터 없음, 운동화\n",
      "1145    기타 모자, 반바지, 반팔 티, 스니커즈/캔버스, 아우터 없음, 장목양말\n",
      "1215              기타 모자, 나일론 팬츠, 바람막이, 반팔 티, 운동화\n",
      "1159       기타 모자, 나일론 팬츠, 반팔 티, 스니커즈/캔버스, 아우터 없음\n",
      "1138      기타 모자, 바람막이, 반바지, 반팔 티, 스니커즈/캔버스, 장목양말\n",
      "Name: 옷 조합, dtype: object\n",
      "0.3333333333333333 0.16666666666666666 0.2222222222222222\n",
      "14번 user, 8.0도 prediction: Index(['기타 모자, 반팔 티, 스니커즈/캔버스, 아우터 없음, 카고바지',\n",
      "       '기타 모자, 나일론 팬츠, 반팔 티, 스니커즈/캔버스, 아우터 없음',\n",
      "       '기타 모자, 반바지, 반팔 티, 스니커즈/캔버스, 아우터 없음, 장목양말'],\n",
      "      dtype='object', name='옷 조합')\n",
      "14번 user, 8.0도 label: 1206     데님팬츠, 반팔 티, 비니, 셔츠/블라우스, 스니커즈/캔버스, 아우터 없음\n",
      "1142         구두/로퍼, 기타 모자, 반바지, 반팔 티, 아우터 없음, 장목양말\n",
      "1171              기타 모자, 나일론 팬츠, 반팔 티, 아우터 없음, 운동화\n",
      "1209               기타 모자, 반팔 티, 스니커즈/캔버스, 집업, 카고바지\n",
      "1188    구두/로퍼, 반바지, 반팔 셔츠/블라우스, 반팔 티, 아우터 없음, 장목양말\n",
      "1190      기타 모자, 반바지, 반팔 티, 스니커즈/캔버스, 아우터 없음, 장목양말\n",
      "Name: 옷 조합, dtype: object\n",
      "0.3333333333333333 0.16666666666666666 0.2222222222222222\n",
      "14번 user, 9.0도 데이터가 부족하여 제외합니다.\n",
      "14번 user, 2.0도 데이터가 부족하여 제외합니다.\n",
      "평균 precision: 0.1884057971014493, 평균 recall: 0.11218081435472736, 평균 f1_score: 0.13799171842650104\n"
     ]
    }
   ],
   "source": [
    "# 예측을 수행하기 위해 모든 user-item에 대한 예측값을 계산\n",
    "p = np.matmul(O.numpy(), np.transpose(U.numpy())) + b.numpy()\n",
    "# user_category_not_valid에 해당하지 않는 경우에 대해 precision, recall, f1_score 계산\n",
    "# 평균을 위한 초기화\n",
    "precision_m, recall_m, f1_score_m, count_m = 0, 0, 0, 0\n",
    "for i in range(n_u):\n",
    "    for category in df_limit['평균기온(°C)'].unique():\n",
    "        \n",
    "        # 실제 온도\n",
    "        # 평균을 적용하고 temp를 빼서 값이 작을수록 실제 온도에 가깝도록 함. 이 때 각 user-item의 사용 횟수를 가중하여 많이 사용한 item이 추천되도록 함\n",
    "        pm = np.power(p + o_mean - category, 2)  -count * 28\n",
    "        my_predictions = pm[:,i]\n",
    "\n",
    "        # sort predictions\n",
    "        ix = tf.argsort(my_predictions, direction='ASCENDING')\n",
    "\n",
    "        df_predict = UI_temp[UI_temp.columns[ix[0:3]]].copy()\n",
    "        # df_predict의 columns와 test_data_df의 '옷 조합' column을 비교하여 일치하는 경우의 개수를 계산\n",
    "        predict = df_predict.columns.astype(str)\n",
    "        \n",
    "        # user i에 대한 예측을 파일로 저장\n",
    "        os.makedirs(f'../data/predictions/male/user_{i+1}', exist_ok=True)\n",
    "        # Save predictions to file in user's directory\n",
    "        with open(f'../data/predictions/male/user_{i+1}/predictions_{category}.txt', 'w') as f:\n",
    "            for item in predict:\n",
    "                f.write(\"%s\\n\" % item)\n",
    "        \n",
    "        if i+1 in user_category_not_valid and category in user_category_not_valid[i+1]:\n",
    "            print(f'{i+1}번 user, {category}도 데이터가 부족하여 제외합니다.')\n",
    "            continue\n",
    "        \n",
    "        count_m += 1\n",
    "        \n",
    "        label = test_data_df[(test_data_df['userId'] == i+1) & (test_data_df['평균기온(°C)'] == category)]['옷 조합'].astype(str)\n",
    "        \n",
    "        precision = len(set(predict) & set(label)) / len(set(predict))\n",
    "        print(f'{i+1}번 user, {category}도 prediction: {predict}')\n",
    "        print(f'{i+1}번 user, {category}도 label: {label}')\n",
    "        recall = len(set(predict) & set(label)) / len(set(label))\n",
    "        if precision + recall == 0:\n",
    "            '''print(f'0인 경우')\n",
    "            print(f'{i+1}번 user, {category}도 예측 결과: {predict}, 실제 결과: {label} ')'''  \n",
    "            f1_score = 0\n",
    "        else:\n",
    "            '''print(f'0이 아닌 경우')\n",
    "            print(f'{i+1}번 user, {category}도 예측 결과: {predict}, 실제 결과: {label} ')'''  \n",
    "            f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "        precision_m += precision\n",
    "        recall_m += recall\n",
    "        f1_score_m += f1_score\n",
    "        print(precision, recall, f1_score)\n",
    "precision_m /= count_m\n",
    "recall_m /= count_m\n",
    "f1_score_m /= count_m\n",
    "print(f'평균 precision: {precision_m}, 평균 recall: {recall_m}, 평균 f1_score: {f1_score_m}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ondoset",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
