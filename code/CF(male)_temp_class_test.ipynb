{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-14 02:30:51.380204: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-14 02:30:51.758542: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-14 02:30:51.758610: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-14 02:30:51.820485: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-14 02:30:52.018557: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-14 02:30:53.318625: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_version = '1.0'\n",
    "# latent factor의 수\n",
    "num_features = 30\n",
    "# iteration 수\n",
    "iterations = 140\n",
    "# learning_rate \n",
    "learning_rate = 1e-1\n",
    "# lambda\n",
    "lambda_ = 1\n",
    "# count_weight\n",
    "count_weight = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장된 모델 버전 및 체크포인트 경로 설정\n",
    "checkpoint_path = f'../model/CF/{model_version}/'\n",
    "\n",
    "# CSV 파일 불러오기\n",
    "UI_temp = pd.read_csv(checkpoint_path + 'UI_temp.csv').drop('userId', axis=1)\n",
    "UI_count_div = pd.read_csv(checkpoint_path + 'UI_count_div.csv').drop('userId', axis=1)\n",
    "test_for_loss = pd.read_csv(checkpoint_path + 'test_for_loss.csv')\n",
    "test_data_df = pd.read_csv(checkpoint_path + 'test_data_df.csv')\n",
    "user_category_not_valid_df = pd.read_csv(checkpoint_path + 'user_category_not_valid.csv')\n",
    "category_df = pd.read_csv(checkpoint_path + 'category.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = category_df.values[0, 1:]\n",
    "labels = category_df.columns[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels의 dtype을 float64로 변경\n",
    "labels = labels.astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(696, 14)\n"
     ]
    }
   ],
   "source": [
    "# CF를 위한 초기값 설정\n",
    "Y = np.array(UI_temp) \n",
    "Y = Y.T\n",
    "count = np.array(UI_count_div)\n",
    "count = count.T\n",
    "print(Y.shape)\n",
    "R = Y != 0 \n",
    "n_u = Y.shape[1]\n",
    "n_o = Y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기록이 존재하는 값의 평균을 구함\n",
    "o_sum = Y.sum(axis=1)\n",
    "o_count = R.sum(axis=1)\n",
    "o_mean = o_sum / o_count\n",
    "o_mean = o_mean.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_stand = Y - (o_mean * R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-14 02:30:54.781093: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-14 02:30:55.209227: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-14 02:30:55.209273: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-14 02:30:55.215076: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-14 02:30:55.215132: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-14 02:30:55.215148: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-14 02:30:55.413368: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-14 02:30:55.413820: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-14 02:30:55.413839: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-05-14 02:30:55.414085: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-14 02:30:55.414393: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3600 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# user, outfit의 수\n",
    "n_o, n_u = Y.shape\n",
    "\n",
    "# (U,O)를 초기화하고 tf.Variable로 등록하여 추적\n",
    "tf.random.set_seed(1234) # for consistent results\n",
    "U = tf.Variable(tf.random.normal((n_u,  num_features),dtype=tf.float64),  name='U')\n",
    "O = tf.Variable(tf.random.normal((n_o, num_features),dtype=tf.float64),  name='O')\n",
    "b = tf.Variable(tf.random.normal((1,          n_u),   dtype=tf.float64),  name='b')\n",
    "\n",
    "# optimizer 초기화\n",
    "optimizer = keras.optimizers.Adam(learning_rate = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_variables_optimizer(variables, optimizer, checkpoint_path):\n",
    "    checkpoint = tf.train.Checkpoint(variables=variables, optimizer=optimizer)\n",
    "    checkpoint.restore(tf.train.latest_checkpoint(checkpoint_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련된 변수 불러오기\n",
    "load_variables_optimizer({\"O\": O, \"U\": U, \"b\": b}, optimizer,  checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'O:0' shape=(696, 30) dtype=float64, numpy=\n",
       "array([[ 0.0003777 , -0.00590412,  0.0019217 , ..., -0.00245451,\n",
       "        -0.00017366,  0.00505472],\n",
       "       [-0.00038296, -0.00565587,  0.00185378, ..., -0.00129054,\n",
       "        -0.00178141,  0.00539561],\n",
       "       [-0.00095602, -0.00346697,  0.00042633, ...,  0.00296692,\n",
       "        -0.00146871,  0.00343953],\n",
       "       ...,\n",
       "       [-0.00346979,  0.00183975,  0.0008086 , ...,  0.00017552,\n",
       "         0.00282561, -0.00231453],\n",
       "       [-0.00124138, -0.00508827,  0.00059356, ...,  0.00228199,\n",
       "        -0.00126017,  0.00360561],\n",
       "       [ 0.0010426 , -0.0005276 ,  0.00076045, ..., -0.00083188,\n",
       "         0.00085243, -0.00150309]])>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cofi_cost_func_v(O, U, b, Y, R, lambda_):\n",
    "    j = (tf.linalg.matmul(O, tf.transpose(U)) + b - Y )*R\n",
    "    J = 0.5 * tf.reduce_sum(j**2) + (lambda_/2) * (tf.reduce_sum(O**2) + tf.reduce_sum(U**2))\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(O, U, b, o_mean, count, count_weight, df, UI_temp, labels, user_category_not_valid) :\n",
    "    # 예측을 수행하기 위해 모든 user-item에 대한 예측값을 계산\n",
    "    p = np.matmul(O.numpy(), np.transpose(U.numpy())) + b.numpy()\n",
    "    # user_category_not_valid에 해당하지 않는 경우에 대해 precision, recall, f1_score 계산\n",
    "    # 평균을 위한 초기화\n",
    "    precision_m, recall_m, f1_score_m, count_m = 0, 0, 0, 0\n",
    "    for i in range(UI_temp.shape[0]):\n",
    "        for category in labels:\n",
    "            \n",
    "            # 실제 온도\n",
    "            # 평균을 적용하고 temp를 빼서 값이 작을수록 실제 온도에 가깝도록 함. 이 때 각 user-item의 사용 횟수를 가중하여 많이 사용한 item이 추천되도록 함\n",
    "            pm = np.power(p + o_mean - category, 2)  -count * count_weight\n",
    "            my_predictions = pm[:,i]\n",
    "\n",
    "            # sort predictions\n",
    "            ix = tf.argsort(my_predictions, direction='ASCENDING')\n",
    "\n",
    "            df_predict = UI_temp[UI_temp.columns[ix[0:3]]].copy()\n",
    "            df_predict = df_predict.round(0)\n",
    "            # df_predict의 columns와 test_data_df의 '옷 조합' column을 비교하여 일치하는 경우의 개수를 계산\n",
    "            predict = df_predict.columns.astype(str)\n",
    "            \n",
    "            if i+1 in user_category_not_valid and category in user_category_not_valid[i+1]:\n",
    "                continue\n",
    "            \n",
    "            label = df[(df['userId'] == i+1) & (df['평균기온(°C)'] == category)]['옷 조합'].astype(str)\n",
    "            # label이 UI_temp의 column에 포함되지 않는다면 제외\n",
    "            label = label[label.isin(UI_temp.columns)]\n",
    "            # label에 어떠한 옷 조합도 포함되지 않을 시 지표를 측정하지 않음\n",
    "            if label.shape[0] == 0:\n",
    "                continue\n",
    "            \n",
    "            count_m += 1\n",
    "            precision = len(set(predict) & set(label)) / len(set(predict))\n",
    "            recall = len(set(predict) & set(label)) / len(set(label))\n",
    "            if precision + recall == 0: \n",
    "                f1_score = 0\n",
    "            else:\n",
    "                f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "            precision_m += precision\n",
    "            recall_m += recall\n",
    "            f1_score_m += f1_score\n",
    "    precision_m /= count_m\n",
    "    recall_m /= count_m\n",
    "    f1_score_m /= count_m\n",
    "    return precision_m, recall_m, f1_score_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-14 02:31:00.096888: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "precision, recall, f1_score = test(O, U, b, o_mean, count, count_weight, test_data_df, UI_temp, labels, user_category_not_valid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평균 precision: 0.42028985507246375, 평균 recall: 0.16773262968915145, 평균 f1_score: 0.2365935996370779\n"
     ]
    }
   ],
   "source": [
    "print(f'평균 precision: {precision}, 평균 recall: {recall}, 평균 f1_score: {f1_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'precision': [precision], 'recall': [recall], 'f1_score': [f1_score]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = json.dumps(data)\n",
    "print(json_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ondoset",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
