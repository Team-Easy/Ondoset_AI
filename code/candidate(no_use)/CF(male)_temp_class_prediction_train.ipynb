{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_version = '1.0'\n",
    "# latent factor의 수\n",
    "num_features = 30\n",
    "# iteration 수\n",
    "iterations = 140\n",
    "# learning_rate \n",
    "learning_rate = 1e-1\n",
    "# lambda\n",
    "lambda_ = 1\n",
    "# count_weight\n",
    "count_weight = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장된 모델 버전 및 체크포인트 경로 설정\n",
    "checkpoint_path = f'../model/{model_version}/'\n",
    "\n",
    "# CSV 파일 불러오기\n",
    "UI_temp = pd.read_csv(checkpoint_path + 'UI_temp.csv').drop('userId', axis=1)\n",
    "UI_count_div = pd.read_csv(checkpoint_path + 'UI_count_div.csv').drop('userId', axis=1)\n",
    "test_for_loss = pd.read_csv(checkpoint_path + 'test_for_loss.csv')\n",
    "test_data_df = pd.read_csv(checkpoint_path + 'test_data_df.csv')\n",
    "user_category_not_valid_df = pd.read_csv(checkpoint_path + 'user_category_not_valid.csv')\n",
    "category_df = pd.read_csv(checkpoint_path + 'category.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = category_df.values[0, 1:]\n",
    "labels = category_df.columns[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels의 dtype을 float64로 변경\n",
    "labels = labels.astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(570, 14)\n"
     ]
    }
   ],
   "source": [
    "# CF를 위한 초기값 설정\n",
    "Y = np.array(UI_temp) \n",
    "Y = Y.T\n",
    "count = np.array(UI_count_div)\n",
    "count = count.T\n",
    "print(Y.shape)\n",
    "R = Y != 0 \n",
    "n_u = Y.shape[1]\n",
    "n_o = Y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기록이 존재하는 값의 평균을 구함\n",
    "o_sum = Y.sum(axis=1)\n",
    "o_count = R.sum(axis=1)\n",
    "o_mean = o_sum / o_count\n",
    "o_mean = o_mean.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_stand = Y - (o_mean * R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n"
     ]
    }
   ],
   "source": [
    "# user, outfit의 수\n",
    "n_o, n_u = Y.shape\n",
    "\n",
    "# (U,O)를 초기화하고 tf.Variable로 등록하여 추적\n",
    "tf.random.set_seed(1234) # for consistent results\n",
    "U = tf.Variable(tf.random.normal((n_u,  num_features),dtype=tf.float64),  name='U')\n",
    "O = tf.Variable(tf.random.normal((n_o, num_features),dtype=tf.float64),  name='O')\n",
    "b = tf.Variable(tf.random.normal((1,          n_u),   dtype=tf.float64),  name='b')\n",
    "\n",
    "# optimizer 초기화\n",
    "optimizer = keras.optimizers.Adam(learning_rate = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_variables_optimizer(variables, optimizer, checkpoint_path):\n",
    "    checkpoint = tf.train.Checkpoint(variables=variables, optimizer=optimizer)\n",
    "    checkpoint.restore(tf.train.latest_checkpoint(checkpoint_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련된 변수 불러오기\n",
    "load_variables_optimizer({\"O\": O, \"U\": U, \"b\": b}, optimizer,  checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'O:0' shape=(570, 30) dtype=float64, numpy=\n",
       "array([[ 0.00010132, -0.00298993,  0.00601141, ..., -0.00284908,\n",
       "         0.00147215,  0.00494636],\n",
       "       [ 0.00022328, -0.00301111,  0.00572545, ..., -0.00224591,\n",
       "         0.0009839 ,  0.00580692],\n",
       "       [-0.00872225,  0.00500805, -0.00547501, ...,  0.00423807,\n",
       "        -0.00124386, -0.00709001],\n",
       "       ...,\n",
       "       [-0.00756777,  0.00470383, -0.00470229, ...,  0.00451384,\n",
       "        -0.00275748, -0.00574044],\n",
       "       [-0.00146283, -0.00036365,  0.00176229, ..., -0.00202911,\n",
       "        -0.00229116,  0.00182291],\n",
       "       [ 0.00089593, -0.00038134, -0.00109004, ...,  0.00093187,\n",
       "         0.00316914, -0.00164165]])>"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cofi_cost_func_v(O, U, b, Y, R, lambda_):\n",
    "    j = (tf.linalg.matmul(O, tf.transpose(U)) + b - Y )*R\n",
    "    J = 0.5 * tf.reduce_sum(j**2) + (lambda_/2) * (tf.reduce_sum(O**2) + tf.reduce_sum(U**2))\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(O, U, b, o_mean, count, count_weight, UI_temp, labels) :\n",
    "    # 예측을 수행하기 위해 모든 user-item에 대한 예측값을 계산\n",
    "    p = np.matmul(O.numpy(), np.transpose(U.numpy())) + b.numpy()\n",
    "    # user_category_not_valid에 해당하지 않는 경우에 대해 precision, recall, f1_score 계산\n",
    "    # 평균을 위한 초기화\n",
    "    for i in range(UI_temp.shape[0]):\n",
    "        for category in labels:\n",
    "            \n",
    "            # 실제 온도\n",
    "            # 평균을 적용하고 temp를 빼서 값이 작을수록 실제 온도에 가깝도록 함. 이 때 각 user-item의 사용 횟수를 가중하여 많이 사용한 item이 추천되도록 함\n",
    "            pm = np.power(p + o_mean - category, 2)  -count * count_weight\n",
    "            my_predictions = pm[:,i]\n",
    "\n",
    "            # sort predictions\n",
    "            ix = tf.argsort(my_predictions, direction='ASCENDING')\n",
    "\n",
    "            df_predict = UI_temp[UI_temp.columns[ix[0:3]]].copy()\n",
    "            df_predict = df_predict.round(0)\n",
    "            # df_predict의 columns와 test_data_df의 '옷 조합' column을 비교하여 일치하는 경우의 개수를 계산\n",
    "            predict = df_predict.columns.astype(str)\n",
    "            \n",
    "            # user i에 대한 예측을 파일로 저장\n",
    "            os.makedirs(f'../data/predictions/male/user_{i+1}', exist_ok=True)\n",
    "            # Save predictions to file in user's directory\n",
    "            with open(f'../data/predictions/male/user_{i+1}/predictions_{category}.txt', 'w') as f:\n",
    "                for item in predict:\n",
    "                    f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(O, U, b, o_mean, count, count_weight, UI_temp, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=13051.930810247874>"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cofi_cost_func_v(O,U,b,Y,R,lambda_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ondoset",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
